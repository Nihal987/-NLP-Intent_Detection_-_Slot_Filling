{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intent+Slot_filling.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"15MsJQPHijskQ8_1qhFANYrMYO6H-fiVO","authorship_tag":"ABX9TyNVuLlJpz31Nygm5wuHKNqZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Add your file location here"],"metadata":{"id":"n79qzo1ykami"}},{"cell_type":"code","source":["cd '/content/drive/MyDrive/NLP_Self/Intent_Detection_&_Slot_Filling'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDViYIXNkXJ8","executionInfo":{"status":"ok","timestamp":1646357226816,"user_tz":300,"elapsed":168,"user":{"displayName":"nihal antony","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpJB54aGbXtcirQ54x0HCtSxafskicA4J1MzA0tA=s64","userId":"04347007925849631634"}},"outputId":"44b79630-8567-4285-d0e0-a01d0c1b19dc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP Self/Intent_Detection_&_Slot_Filling\n"]}]},{"cell_type":"markdown","source":["### Install Requirements"],"metadata":{"id":"kE1eHzUAkgx7"}},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"id":"NZWgtn4ykY8A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646357327311,"user_tz":300,"elapsed":98683,"user":{"displayName":"nihal antony","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpJB54aGbXtcirQ54x0HCtSxafskicA4J1MzA0tA=s64","userId":"04347007925849631634"}},"outputId":"dc7813cc-a3ad-41fd-81b5-77dcb2614ce8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.6.0\n","  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n","\u001b[K     |████████████████████████████████| 748.8 MB 19 kB/s \n","\u001b[?25hCollecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 60.9 MB/s \n","\u001b[?25hCollecting seqeval==0.0.12\n","  Downloading seqeval-0.0.12.tar.gz (21 kB)\n","Collecting pytorch-crf==0.7.2\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.21.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.6 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (2019.12.20)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 44.4 MB/s \n","\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->-r requirements.txt (line 3)) (2.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2->-r requirements.txt (line 2)) (3.0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 2)) (7.1.2)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7435 sha256=7f2adb6a698fa3626abb4fa2d9a69cb2d395863e4dc949d7270c3e898b9dcf8e\n","  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\n","Successfully built seqeval\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, torch, seqeval, pytorch-crf\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n","Successfully installed pytorch-crf-0.7.2 sacremoses-0.0.47 sentencepiece-0.1.96 seqeval-0.0.12 tokenizers-0.8.1rc1 torch-1.6.0 transformers-3.0.2\n"]}]},{"cell_type":"markdown","source":["### Training the Model"],"metadata":{"id":"GNEsC-HIkq1b"}},{"cell_type":"code","source":["!python3 main.py --task atis \\\n","                  --model_type roberta \\\n","                  --model_dir atis_model \\\n","                  --do_train --do_eval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VnyQSKXksu6","executionInfo":{"status":"ok","timestamp":1646357997005,"user_tz":300,"elapsed":518466,"user":{"displayName":"nihal antony","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpJB54aGbXtcirQ54x0HCtSxafskicA4J1MzA0tA=s64","userId":"04347007925849631634"}},"outputId":"13c8bace-bffe-438b-ad30-f4e27044d935"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["03/04/2022 01:31:23 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp7qadujrd\n","Downloading: 100% 899k/899k [00:00<00:00, 2.84MB/s]\n","03/04/2022 01:31:24 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","03/04/2022 01:31:24 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","03/04/2022 01:31:24 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpc_3u7t6c\n","Downloading: 100% 456k/456k [00:00<00:00, 1.45MB/s]\n","03/04/2022 01:31:24 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","03/04/2022 01:31:24 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","03/04/2022 01:31:24 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","03/04/2022 01:31:24 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","03/04/2022 01:31:26 - INFO - data_loader -   Creating features from dataset file at ./data\n","03/04/2022 01:31:26 - INFO - data_loader -   LOOKING AT ./data/atis/train\n","03/04/2022 01:31:27 - INFO - data_loader -   Writing example 0 of 4478\n","03/04/2022 01:31:27 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:27 - INFO - data_loader -   guid: train-0\n","03/04/2022 01:31:27 - INFO - data_loader -   tokens: <s> i want to fly from b alt imore to d allas round trip </s>\n","03/04/2022 01:31:27 - INFO - data_loader -   input_ids: 0 118 32835 560 19252 7761 428 3967 28545 560 417 35449 3431 30674 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:27 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 73 0 0 2 114 0 98 99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:27 - INFO - data_loader -   guid: train-1\n","03/04/2022 01:31:27 - INFO - data_loader -   tokens: <s> round trip f ares from b alt imore to phil adelphia less than 1000 d oll ars round trip f ares from den ver to phil adelphia less than 1000 d oll ars round trip f ares from p itt sburgh to phil adelphia less than 1000 d </s>\n","03/04/2022 01:31:27 - INFO - data_loader -   input_ids: 0 3431 30674 506 5347 7761 428 3967 28545 560 39142 45929 1672 5652 20078 417 3937 2726 3431 30674 506 5347 7761 3898 2802 560 39142 45929 1672 5652 20078 417 3937 2726 3431 30674 506 5347 7761 642 2582 39710 560 39142 45929 1672 5652 20078 417 2\n","03/04/2022 01:31:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:27 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   intent_label: 4 (id = 4)\n","03/04/2022 01:31:27 - INFO - data_loader -   slot_labels: 0 98 99 2 0 2 73 0 0 2 114 0 32 2 58 59 0 0 98 99 2 0 2 73 0 2 114 0 32 2 58 59 0 0 98 99 2 0 2 73 0 0 2 114 0 32 2 58 59 0\n","03/04/2022 01:31:27 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:27 - INFO - data_loader -   guid: train-2\n","03/04/2022 01:31:27 - INFO - data_loader -   tokens: <s> show me the fl ights ar ri ving on b alt imore on j une four teenth </s>\n","03/04/2022 01:31:27 - INFO - data_loader -   input_ids: 0 12005 1794 627 4825 6183 271 1069 6645 261 428 3967 28545 261 267 4438 10231 33326 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:27 - INFO - data_loader -   slot_labels: 0 2 2 2 2 0 2 0 0 2 114 0 0 2 14 0 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:27 - INFO - data_loader -   guid: train-3\n","03/04/2022 01:31:27 - INFO - data_loader -   tokens: <s> what are the fl ights which dep art from san fr anc isco fly to w ashington via ind ian apolis and ar rive by 9 pm </s>\n","03/04/2022 01:31:27 - INFO - data_loader -   input_ids: 0 12196 1322 627 4825 6183 5488 17272 2013 7761 14832 12997 3290 15069 19252 560 605 40886 11409 2028 811 20048 463 271 25824 1409 466 1685 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:27 - INFO - data_loader -   slot_labels: 0 2 2 2 2 0 2 2 0 2 73 74 0 0 2 2 114 0 2 103 0 0 2 2 0 25 23 24 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:27 - INFO - data_loader -   guid: train-4\n","03/04/2022 01:31:27 - INFO - data_loader -   tokens: <s> which air lines fly from b oston to w ashington dc via other c ities </s>\n","03/04/2022 01:31:27 - INFO - data_loader -   input_ids: 0 5488 2456 11723 19252 7761 428 40415 560 605 40886 34836 11409 7443 438 2192 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:27 - INFO - data_loader -   intent_label: 5 (id = 5)\n","03/04/2022 01:31:27 - INFO - data_loader -   slot_labels: 0 2 2 0 2 2 73 0 2 114 0 117 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:29 - INFO - data_loader -   Saving features into cached file ./data/cached_train_atis_roberta-base_50\n","03/04/2022 01:31:30 - INFO - data_loader -   Creating features from dataset file at ./data\n","03/04/2022 01:31:30 - INFO - data_loader -   LOOKING AT ./data/atis/dev\n","03/04/2022 01:31:31 - INFO - data_loader -   Writing example 0 of 500\n","03/04/2022 01:31:31 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:31 - INFO - data_loader -   guid: dev-0\n","03/04/2022 01:31:31 - INFO - data_loader -   tokens: <s> i want to fly from b oston at 8 38 am and ar rive in den ver at 11 10 in the morning </s>\n","03/04/2022 01:31:31 - INFO - data_loader -   input_ids: 0 118 32835 560 19252 7761 428 40415 415 398 3170 424 463 271 25824 179 3898 2802 415 1225 698 179 627 24863 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:31 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 73 0 2 52 0 53 2 2 0 2 114 0 2 23 0 2 2 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:31 - INFO - data_loader -   guid: dev-1\n","03/04/2022 01:31:31 - INFO - data_loader -   tokens: <s> show me all round trip fl ights between h ouston and las ve gas </s>\n","03/04/2022 01:31:31 - INFO - data_loader -   input_ids: 0 12005 1794 1250 3431 30674 4825 6183 25784 298 42185 463 15086 548 16306 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:31 - INFO - data_loader -   slot_labels: 0 2 2 2 98 99 2 0 2 73 0 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:31 - INFO - data_loader -   guid: dev-2\n","03/04/2022 01:31:31 - INFO - data_loader -   tokens: <s> i would like some information on a flight from den ver to san fr anc isco on united air lines </s>\n","03/04/2022 01:31:31 - INFO - data_loader -   input_ids: 0 118 14656 3341 12465 31480 261 102 15801 7761 3898 2802 560 14832 12997 3290 15069 261 33557 2456 11723 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:31 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 2 2 2 73 0 2 114 115 0 0 2 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:31 - INFO - data_loader -   guid: dev-3\n","03/04/2022 01:31:31 - INFO - data_loader -   tokens: <s> what are the co ach fl ights between d allas and b alt imore le aving aug ust t enth and return ing aug ust tw elve </s>\n","03/04/2022 01:31:31 - INFO - data_loader -   input_ids: 0 12196 1322 627 876 1488 4825 6183 25784 417 35449 463 428 3967 28545 459 13286 12361 4193 90 28249 463 30921 154 12361 4193 17137 41120 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:31 - INFO - data_loader -   slot_labels: 0 2 2 2 29 0 2 0 2 73 0 2 114 0 0 2 0 41 0 39 0 2 2 0 93 0 92 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:31 - INFO - data_loader -   guid: dev-4\n","03/04/2022 01:31:31 - INFO - data_loader -   tokens: <s> i 'm flying from b oston to the bay area </s>\n","03/04/2022 01:31:31 - INFO - data_loader -   input_ids: 0 118 437 28781 7761 428 40415 560 627 18707 7907 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:31 - INFO - data_loader -   slot_labels: 0 2 0 2 2 73 0 2 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:31 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_atis_roberta-base_50\n","03/04/2022 01:31:31 - INFO - data_loader -   Creating features from dataset file at ./data\n","03/04/2022 01:31:31 - INFO - data_loader -   LOOKING AT ./data/atis/test\n","03/04/2022 01:31:32 - INFO - data_loader -   Writing example 0 of 893\n","03/04/2022 01:31:32 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:32 - INFO - data_loader -   guid: test-0\n","03/04/2022 01:31:32 - INFO - data_loader -   tokens: <s> i would like to find a flight from ch arl otte to las ve gas that makes a stop in st . l ou is </s>\n","03/04/2022 01:31:32 - INFO - data_loader -   input_ids: 0 118 14656 3341 560 26559 102 15801 7761 611 11278 17034 560 15086 548 16306 6025 39082 102 8287 179 620 4 462 1438 354 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:32 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:32 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 2 2 73 0 0 2 114 115 0 2 2 2 2 2 103 0 104 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:32 - INFO - data_loader -   guid: test-1\n","03/04/2022 01:31:32 - INFO - data_loader -   tokens: <s> on ap ril first i need a ticket from t ac oma to san j ose dep art ing before 7 am </s>\n","03/04/2022 01:31:32 - INFO - data_loader -   input_ids: 0 261 1115 20447 9502 118 30484 102 28362 7761 90 1043 4982 560 14832 267 3876 17272 2013 154 23033 406 424 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:32 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   intent_label: 4 (id = 4)\n","03/04/2022 01:31:32 - INFO - data_loader -   slot_labels: 0 2 41 0 39 2 2 2 2 2 73 0 0 2 114 115 0 2 0 0 54 52 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:32 - INFO - data_loader -   guid: test-2\n","03/04/2022 01:31:32 - INFO - data_loader -   tokens: <s> on ap ril first i need a flight going from ph oenix to san die go </s>\n","03/04/2022 01:31:32 - INFO - data_loader -   input_ids: 0 261 1115 20447 9502 118 30484 102 15801 12891 7761 3792 42956 560 14832 18554 2977 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:32 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:32 - INFO - data_loader -   slot_labels: 0 2 41 0 39 2 2 2 2 2 2 73 0 2 114 115 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:32 - INFO - data_loader -   guid: test-3\n","03/04/2022 01:31:32 - INFO - data_loader -   tokens: <s> i would like a flight travel ing one way from ph oenix to san die go on ap ril first </s>\n","03/04/2022 01:31:32 - INFO - data_loader -   input_ids: 0 118 14656 3341 102 15801 28881 154 1264 1970 7761 3792 42956 560 14832 18554 2977 261 1115 20447 9502 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:32 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:32 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 0 98 99 2 73 0 2 114 115 0 2 41 0 39 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   *** Example ***\n","03/04/2022 01:31:32 - INFO - data_loader -   guid: test-4\n","03/04/2022 01:31:32 - INFO - data_loader -   tokens: <s> i would like a flight from or lando to s alt lake city for ap ril first on d elta air lines </s>\n","03/04/2022 01:31:32 - INFO - data_loader -   input_ids: 0 118 14656 3341 102 15801 7761 368 29028 560 29 3967 11985 14853 1990 1115 20447 9502 261 417 25412 2456 11723 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","03/04/2022 01:31:32 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:32 - INFO - data_loader -   intent_label: 12 (id = 12)\n","03/04/2022 01:31:32 - INFO - data_loader -   slot_labels: 0 2 2 2 2 2 2 73 0 2 114 0 115 115 2 41 0 39 2 5 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/04/2022 01:31:33 - INFO - data_loader -   Saving features into cached file ./data/cached_test_atis_roberta-base_50\n","03/04/2022 01:31:33 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppu4jgovp\n","Downloading: 100% 481/481 [00:00<00:00, 406kB/s]\n","03/04/2022 01:31:34 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","03/04/2022 01:31:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","03/04/2022 01:31:34 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","03/04/2022 01:31:34 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"atis\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","03/04/2022 01:31:34 - INFO - transformers.file_utils -   https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8rikvbzu\n","Downloading: 100% 501M/501M [00:14<00:00, 34.8MB/s]\n","03/04/2022 01:31:48 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","03/04/2022 01:31:48 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","03/04/2022 01:31:48 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","03/04/2022 01:31:57 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at roberta-base were not used when initializing JointRoberta: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing JointRoberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing JointRoberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","03/04/2022 01:31:57 - WARNING - transformers.modeling_utils -   Some weights of JointRoberta were not initialized from the model checkpoint at roberta-base and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","03/04/2022 01:32:00 - INFO - trainer -   ***** Running training *****\n","03/04/2022 01:32:00 - INFO - trainer -     Num examples = 4478\n","03/04/2022 01:32:00 - INFO - trainer -     Num Epochs = 10\n","03/04/2022 01:32:00 - INFO - trainer -     Total train batch size = 32\n","03/04/2022 01:32:00 - INFO - trainer -     Gradient Accumulation steps = 1\n","03/04/2022 01:32:00 - INFO - trainer -     Total optimization steps = 1400\n","03/04/2022 01:32:00 - INFO - trainer -     Logging steps = 200\n","03/04/2022 01:32:00 - INFO - trainer -     Save steps = 200\n","Epoch:   0% 0/10 [00:00<?, ?it/s]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<01:04,  2.17it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:47,  2.89it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:42,  3.22it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:39,  3.42it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:38,  3.52it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:37,  3.58it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:36,  3.63it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:35,  3.67it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:35,  3.69it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:35,  3.70it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:34,  3.71it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:34,  3.72it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:34,  3.71it/s]\u001b[A\n","Iteration:  10% 14/140 [00:03<00:33,  3.72it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:33,  3.73it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:33,  3.72it/s]\u001b[A\n","Iteration:  12% 17/140 [00:04<00:33,  3.71it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:32,  3.70it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:32,  3.76it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:32,  3.73it/s]\u001b[A\n","Iteration:  15% 21/140 [00:05<00:32,  3.72it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:31,  3.72it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:31,  3.71it/s]\u001b[A\n","Iteration:  17% 24/140 [00:06<00:31,  3.69it/s]\u001b[A\n","Iteration:  18% 25/140 [00:06<00:30,  3.74it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:30,  3.72it/s]\u001b[A\n","Iteration:  19% 27/140 [00:07<00:30,  3.70it/s]\u001b[A\n","Iteration:  20% 28/140 [00:07<00:30,  3.71it/s]\u001b[A\n","Iteration:  21% 29/140 [00:07<00:29,  3.71it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:29,  3.70it/s]\u001b[A\n","Iteration:  22% 31/140 [00:08<00:29,  3.70it/s]\u001b[A\n","Iteration:  23% 32/140 [00:08<00:29,  3.70it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:28,  3.70it/s]\u001b[A\n","Iteration:  24% 34/140 [00:09<00:28,  3.70it/s]\u001b[A\n","Iteration:  25% 35/140 [00:09<00:28,  3.69it/s]\u001b[A\n","Iteration:  26% 36/140 [00:09<00:28,  3.69it/s]\u001b[A\n","Iteration:  26% 37/140 [00:10<00:27,  3.69it/s]\u001b[A\n","Iteration:  27% 38/140 [00:10<00:27,  3.70it/s]\u001b[A\n","Iteration:  28% 39/140 [00:10<00:27,  3.69it/s]\u001b[A\n","Iteration:  29% 40/140 [00:10<00:27,  3.69it/s]\u001b[A\n","Iteration:  29% 41/140 [00:11<00:26,  3.69it/s]\u001b[A\n","Iteration:  30% 42/140 [00:11<00:26,  3.69it/s]\u001b[A\n","Iteration:  31% 43/140 [00:11<00:26,  3.68it/s]\u001b[A\n","Iteration:  31% 44/140 [00:12<00:26,  3.68it/s]\u001b[A\n","Iteration:  32% 45/140 [00:12<00:25,  3.67it/s]\u001b[A\n","Iteration:  33% 46/140 [00:12<00:25,  3.68it/s]\u001b[A\n","Iteration:  34% 47/140 [00:12<00:25,  3.66it/s]\u001b[A\n","Iteration:  34% 48/140 [00:13<00:25,  3.66it/s]\u001b[A\n","Iteration:  35% 49/140 [00:13<00:24,  3.68it/s]\u001b[A\n","Iteration:  36% 50/140 [00:13<00:24,  3.68it/s]\u001b[A\n","Iteration:  36% 51/140 [00:13<00:24,  3.68it/s]\u001b[A\n","Iteration:  37% 52/140 [00:14<00:23,  3.67it/s]\u001b[A\n","Iteration:  38% 53/140 [00:14<00:23,  3.68it/s]\u001b[A\n","Iteration:  39% 54/140 [00:14<00:23,  3.67it/s]\u001b[A\n","Iteration:  39% 55/140 [00:15<00:23,  3.67it/s]\u001b[A\n","Iteration:  40% 56/140 [00:15<00:22,  3.68it/s]\u001b[A\n","Iteration:  41% 57/140 [00:15<00:22,  3.67it/s]\u001b[A\n","Iteration:  41% 58/140 [00:15<00:22,  3.68it/s]\u001b[A\n","Iteration:  42% 59/140 [00:16<00:22,  3.67it/s]\u001b[A\n","Iteration:  43% 60/140 [00:16<00:22,  3.63it/s]\u001b[A\n","Iteration:  44% 61/140 [00:16<00:21,  3.62it/s]\u001b[A\n","Iteration:  44% 62/140 [00:16<00:21,  3.64it/s]\u001b[A\n","Iteration:  45% 63/140 [00:17<00:21,  3.65it/s]\u001b[A\n","Iteration:  46% 64/140 [00:17<00:20,  3.66it/s]\u001b[A\n","Iteration:  46% 65/140 [00:17<00:20,  3.66it/s]\u001b[A\n","Iteration:  47% 66/140 [00:18<00:20,  3.66it/s]\u001b[A\n","Iteration:  48% 67/140 [00:18<00:19,  3.66it/s]\u001b[A\n","Iteration:  49% 68/140 [00:18<00:19,  3.64it/s]\u001b[A\n","Iteration:  49% 69/140 [00:18<00:19,  3.70it/s]\u001b[A\n","Iteration:  50% 70/140 [00:19<00:19,  3.66it/s]\u001b[A\n","Iteration:  51% 71/140 [00:19<00:18,  3.64it/s]\u001b[A\n","Iteration:  51% 72/140 [00:19<00:18,  3.62it/s]\u001b[A\n","Iteration:  52% 73/140 [00:19<00:18,  3.64it/s]\u001b[A\n","Iteration:  53% 74/140 [00:20<00:18,  3.65it/s]\u001b[A\n","Iteration:  54% 75/140 [00:20<00:17,  3.66it/s]\u001b[A\n","Iteration:  54% 76/140 [00:20<00:17,  3.65it/s]\u001b[A\n","Iteration:  55% 77/140 [00:21<00:17,  3.65it/s]\u001b[A\n","Iteration:  56% 78/140 [00:21<00:17,  3.65it/s]\u001b[A\n","Iteration:  56% 79/140 [00:21<00:16,  3.65it/s]\u001b[A\n","Iteration:  57% 80/140 [00:21<00:16,  3.65it/s]\u001b[A\n","Iteration:  58% 81/140 [00:22<00:16,  3.66it/s]\u001b[A\n","Iteration:  59% 82/140 [00:22<00:15,  3.64it/s]\u001b[A\n","Iteration:  59% 83/140 [00:22<00:15,  3.64it/s]\u001b[A\n","Iteration:  60% 84/140 [00:22<00:15,  3.65it/s]\u001b[A\n","Iteration:  61% 85/140 [00:23<00:15,  3.65it/s]\u001b[A\n","Iteration:  61% 86/140 [00:23<00:14,  3.62it/s]\u001b[A\n","Iteration:  62% 87/140 [00:23<00:14,  3.63it/s]\u001b[A\n","Iteration:  63% 88/140 [00:24<00:14,  3.64it/s]\u001b[A\n","Iteration:  64% 89/140 [00:24<00:13,  3.66it/s]\u001b[A\n","Iteration:  64% 90/140 [00:24<00:13,  3.63it/s]\u001b[A\n","Iteration:  65% 91/140 [00:24<00:13,  3.64it/s]\u001b[A\n","Iteration:  66% 92/140 [00:25<00:13,  3.65it/s]\u001b[A\n","Iteration:  66% 93/140 [00:25<00:12,  3.66it/s]\u001b[A\n","Iteration:  67% 94/140 [00:25<00:12,  3.64it/s]\u001b[A\n","Iteration:  68% 95/140 [00:26<00:12,  3.65it/s]\u001b[A\n","Iteration:  69% 96/140 [00:26<00:12,  3.64it/s]\u001b[A\n","Iteration:  69% 97/140 [00:26<00:11,  3.64it/s]\u001b[A\n","Iteration:  70% 98/140 [00:26<00:11,  3.64it/s]\u001b[A\n","Iteration:  71% 99/140 [00:27<00:11,  3.65it/s]\u001b[A\n","Iteration:  71% 100/140 [00:27<00:10,  3.65it/s]\u001b[A\n","Iteration:  72% 101/140 [00:27<00:10,  3.65it/s]\u001b[A\n","Iteration:  73% 102/140 [00:27<00:10,  3.65it/s]\u001b[A\n","Iteration:  74% 103/140 [00:28<00:10,  3.64it/s]\u001b[A\n","Iteration:  74% 104/140 [00:28<00:09,  3.63it/s]\u001b[A\n","Iteration:  75% 105/140 [00:28<00:09,  3.62it/s]\u001b[A\n","Iteration:  76% 106/140 [00:29<00:09,  3.64it/s]\u001b[A\n","Iteration:  76% 107/140 [00:29<00:09,  3.64it/s]\u001b[A\n","Iteration:  77% 108/140 [00:29<00:08,  3.65it/s]\u001b[A\n","Iteration:  78% 109/140 [00:29<00:08,  3.64it/s]\u001b[A\n","Iteration:  79% 110/140 [00:30<00:08,  3.63it/s]\u001b[A\n","Iteration:  79% 111/140 [00:30<00:07,  3.64it/s]\u001b[A\n","Iteration:  80% 112/140 [00:30<00:07,  3.64it/s]\u001b[A\n","Iteration:  81% 113/140 [00:30<00:07,  3.63it/s]\u001b[A\n","Iteration:  81% 114/140 [00:31<00:07,  3.64it/s]\u001b[A\n","Iteration:  82% 115/140 [00:31<00:06,  3.63it/s]\u001b[A\n","Iteration:  83% 116/140 [00:31<00:06,  3.61it/s]\u001b[A\n","Iteration:  84% 117/140 [00:32<00:06,  3.62it/s]\u001b[A\n","Iteration:  84% 118/140 [00:32<00:06,  3.62it/s]\u001b[A\n","Iteration:  85% 119/140 [00:32<00:05,  3.62it/s]\u001b[A\n","Iteration:  86% 120/140 [00:32<00:05,  3.67it/s]\u001b[A\n","Iteration:  86% 121/140 [00:33<00:05,  3.65it/s]\u001b[A\n","Iteration:  87% 122/140 [00:33<00:04,  3.63it/s]\u001b[A\n","Iteration:  88% 123/140 [00:33<00:04,  3.63it/s]\u001b[A\n","Iteration:  89% 124/140 [00:33<00:04,  3.62it/s]\u001b[A\n","Iteration:  89% 125/140 [00:34<00:04,  3.62it/s]\u001b[A\n","Iteration:  90% 126/140 [00:34<00:03,  3.62it/s]\u001b[A\n","Iteration:  91% 127/140 [00:34<00:03,  3.62it/s]\u001b[A\n","Iteration:  91% 128/140 [00:35<00:03,  3.63it/s]\u001b[A\n","Iteration:  92% 129/140 [00:35<00:03,  3.63it/s]\u001b[A\n","Iteration:  93% 130/140 [00:35<00:02,  3.63it/s]\u001b[A\n","Iteration:  94% 131/140 [00:35<00:02,  3.63it/s]\u001b[A\n","Iteration:  94% 132/140 [00:36<00:02,  3.63it/s]\u001b[A\n","Iteration:  95% 133/140 [00:36<00:01,  3.62it/s]\u001b[A\n","Iteration:  96% 134/140 [00:36<00:01,  3.63it/s]\u001b[A\n","Iteration:  96% 135/140 [00:37<00:01,  3.63it/s]\u001b[A\n","Iteration:  97% 136/140 [00:37<00:01,  3.62it/s]\u001b[A\n","Iteration:  98% 137/140 [00:37<00:00,  3.62it/s]\u001b[A\n","Iteration:  99% 138/140 [00:37<00:00,  3.62it/s]\u001b[A\n","Iteration:  99% 139/140 [00:38<00:00,  3.61it/s]\u001b[A\n","Iteration: 100% 140/140 [00:38<00:00,  3.65it/s]\n","Epoch:  10% 1/10 [00:38<05:45, 38.39s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:38,  3.61it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:38,  3.62it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:38,  3.58it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:37,  3.60it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:37,  3.59it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:37,  3.60it/s]\u001b[A\n","Iteration:   5% 7/140 [00:01<00:36,  3.60it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:36,  3.60it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:36,  3.60it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:36,  3.61it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:35,  3.59it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:35,  3.59it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:35,  3.59it/s]\u001b[A\n","Iteration:  10% 14/140 [00:03<00:35,  3.60it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:34,  3.59it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:34,  3.58it/s]\u001b[A\n","Iteration:  12% 17/140 [00:04<00:34,  3.59it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:34,  3.58it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:33,  3.59it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:33,  3.58it/s]\u001b[A\n","Iteration:  15% 21/140 [00:05<00:33,  3.59it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:32,  3.60it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:32,  3.59it/s]\u001b[A\n","Iteration:  17% 24/140 [00:06<00:31,  3.63it/s]\u001b[A\n","Iteration:  18% 25/140 [00:06<00:31,  3.63it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:31,  3.62it/s]\u001b[A\n","Iteration:  19% 27/140 [00:07<00:31,  3.61it/s]\u001b[A\n","Iteration:  20% 28/140 [00:07<00:31,  3.59it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:30,  3.59it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:30,  3.59it/s]\u001b[A\n","Iteration:  22% 31/140 [00:08<00:30,  3.59it/s]\u001b[A\n","Iteration:  23% 32/140 [00:08<00:30,  3.58it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:29,  3.58it/s]\u001b[A\n","Iteration:  24% 34/140 [00:09<00:29,  3.59it/s]\u001b[A\n","Iteration:  25% 35/140 [00:09<00:29,  3.60it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:29,  3.58it/s]\u001b[A\n","Iteration:  26% 37/140 [00:10<00:28,  3.58it/s]\u001b[A\n","Iteration:  27% 38/140 [00:10<00:28,  3.59it/s]\u001b[A\n","Iteration:  28% 39/140 [00:10<00:28,  3.58it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:27,  3.57it/s]\u001b[A\n","Iteration:  29% 41/140 [00:11<00:27,  3.58it/s]\u001b[A\n","Iteration:  30% 42/140 [00:11<00:27,  3.57it/s]\u001b[A\n","Iteration:  31% 43/140 [00:11<00:27,  3.57it/s]\u001b[A\n","Iteration:  31% 44/140 [00:12<00:26,  3.58it/s]\u001b[A\n","Iteration:  32% 45/140 [00:12<00:26,  3.58it/s]\u001b[A\n","Iteration:  33% 46/140 [00:12<00:26,  3.57it/s]\u001b[A\n","Iteration:  34% 47/140 [00:13<00:26,  3.57it/s]\u001b[A\n","Iteration:  34% 48/140 [00:13<00:25,  3.58it/s]\u001b[A\n","Iteration:  35% 49/140 [00:13<00:25,  3.58it/s]\u001b[A\n","Iteration:  36% 50/140 [00:13<00:25,  3.57it/s]\u001b[A\n","Iteration:  36% 51/140 [00:14<00:24,  3.56it/s]\u001b[A\n","Iteration:  37% 52/140 [00:14<00:24,  3.57it/s]\u001b[A\n","Iteration:  38% 53/140 [00:14<00:24,  3.57it/s]\u001b[A\n","Iteration:  39% 54/140 [00:15<00:24,  3.56it/s]\u001b[A\n","Iteration:  39% 55/140 [00:15<00:23,  3.56it/s]\u001b[A\n","Iteration:  40% 56/140 [00:15<00:23,  3.57it/s]\u001b[A\n","Iteration:  41% 57/140 [00:15<00:23,  3.57it/s]\u001b[A\n","Iteration:  41% 58/140 [00:16<00:22,  3.58it/s]\u001b[A\n","Iteration:  42% 59/140 [00:16<00:22,  3.56it/s]\u001b[A03/04/2022 01:32:55 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:32:55 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:32:55 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  6.59it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:00,  6.39it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  6.31it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  6.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  6.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:00<00:00,  6.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  6.19it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  6.34it/s]\n","03/04/2022 01:32:57 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:32:57 - INFO - trainer -     intent_acc = 0.966\n","03/04/2022 01:32:57 - INFO - trainer -     loss = 0.38896409794688225\n","03/04/2022 01:32:57 - INFO - trainer -     sementic_frame_acc = 0.67\n","03/04/2022 01:32:57 - INFO - trainer -     slot_f1 = 0.8685282140779523\n","03/04/2022 01:32:57 - INFO - trainer -     slot_precision = 0.8640046296296297\n","03/04/2022 01:32:57 - INFO - trainer -     slot_recall = 0.8730994152046784\n","03/04/2022 01:32:57 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:33:12 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:33:12 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  43% 60/140 [00:33<07:01,  5.26s/it]\u001b[A\n","Iteration:  44% 61/140 [00:33<04:59,  3.79s/it]\u001b[A\n","Iteration:  44% 62/140 [00:33<03:33,  2.73s/it]\u001b[A\n","Iteration:  45% 63/140 [00:34<02:33,  2.00s/it]\u001b[A\n","Iteration:  46% 64/140 [00:34<01:52,  1.48s/it]\u001b[A\n","Iteration:  46% 65/140 [00:34<01:24,  1.12s/it]\u001b[A\n","Iteration:  47% 66/140 [00:35<01:04,  1.15it/s]\u001b[A\n","Iteration:  48% 67/140 [00:35<00:50,  1.44it/s]\u001b[A\n","Iteration:  49% 68/140 [00:35<00:40,  1.76it/s]\u001b[A\n","Iteration:  49% 69/140 [00:35<00:34,  2.07it/s]\u001b[A\n","Iteration:  50% 70/140 [00:36<00:29,  2.37it/s]\u001b[A\n","Iteration:  51% 71/140 [00:36<00:26,  2.63it/s]\u001b[A\n","Iteration:  51% 72/140 [00:36<00:23,  2.86it/s]\u001b[A\n","Iteration:  52% 73/140 [00:37<00:22,  3.04it/s]\u001b[A\n","Iteration:  53% 74/140 [00:37<00:20,  3.18it/s]\u001b[A\n","Iteration:  54% 75/140 [00:37<00:19,  3.29it/s]\u001b[A\n","Iteration:  54% 76/140 [00:37<00:19,  3.37it/s]\u001b[A\n","Iteration:  55% 77/140 [00:38<00:18,  3.43it/s]\u001b[A\n","Iteration:  56% 78/140 [00:38<00:17,  3.45it/s]\u001b[A\n","Iteration:  56% 79/140 [00:38<00:17,  3.47it/s]\u001b[A\n","Iteration:  57% 80/140 [00:39<00:17,  3.50it/s]\u001b[A\n","Iteration:  58% 81/140 [00:39<00:16,  3.50it/s]\u001b[A\n","Iteration:  59% 82/140 [00:39<00:17,  3.40it/s]\u001b[A\n","Iteration:  59% 83/140 [00:39<00:16,  3.44it/s]\u001b[A\n","Iteration:  60% 84/140 [00:40<00:16,  3.47it/s]\u001b[A\n","Iteration:  61% 85/140 [00:40<00:15,  3.49it/s]\u001b[A\n","Iteration:  61% 86/140 [00:40<00:15,  3.46it/s]\u001b[A\n","Iteration:  62% 87/140 [00:41<00:15,  3.45it/s]\u001b[A\n","Iteration:  63% 88/140 [00:41<00:14,  3.47it/s]\u001b[A\n","Iteration:  64% 89/140 [00:41<00:14,  3.48it/s]\u001b[A\n","Iteration:  64% 90/140 [00:41<00:14,  3.49it/s]\u001b[A\n","Iteration:  65% 91/140 [00:42<00:14,  3.49it/s]\u001b[A\n","Iteration:  66% 92/140 [00:42<00:13,  3.50it/s]\u001b[A\n","Iteration:  66% 93/140 [00:42<00:13,  3.49it/s]\u001b[A\n","Iteration:  67% 94/140 [00:43<00:13,  3.45it/s]\u001b[A\n","Iteration:  68% 95/140 [00:43<00:13,  3.45it/s]\u001b[A\n","Iteration:  69% 96/140 [00:43<00:12,  3.48it/s]\u001b[A\n","Iteration:  69% 97/140 [00:43<00:12,  3.48it/s]\u001b[A\n","Iteration:  70% 98/140 [00:44<00:12,  3.49it/s]\u001b[A\n","Iteration:  71% 99/140 [00:44<00:11,  3.49it/s]\u001b[A\n","Iteration:  71% 100/140 [00:44<00:11,  3.49it/s]\u001b[A\n","Iteration:  72% 101/140 [00:45<00:11,  3.49it/s]\u001b[A\n","Iteration:  73% 102/140 [00:45<00:10,  3.51it/s]\u001b[A\n","Iteration:  74% 103/140 [00:45<00:10,  3.52it/s]\u001b[A\n","Iteration:  74% 104/140 [00:45<00:10,  3.53it/s]\u001b[A\n","Iteration:  75% 105/140 [00:46<00:09,  3.53it/s]\u001b[A\n","Iteration:  76% 106/140 [00:46<00:09,  3.50it/s]\u001b[A\n","Iteration:  76% 107/140 [00:46<00:09,  3.49it/s]\u001b[A\n","Iteration:  77% 108/140 [00:47<00:09,  3.51it/s]\u001b[A\n","Iteration:  78% 109/140 [00:47<00:08,  3.52it/s]\u001b[A\n","Iteration:  79% 110/140 [00:47<00:08,  3.53it/s]\u001b[A\n","Iteration:  79% 111/140 [00:47<00:08,  3.53it/s]\u001b[A\n","Iteration:  80% 112/140 [00:48<00:07,  3.53it/s]\u001b[A\n","Iteration:  81% 113/140 [00:48<00:07,  3.54it/s]\u001b[A\n","Iteration:  81% 114/140 [00:48<00:07,  3.54it/s]\u001b[A\n","Iteration:  82% 115/140 [00:49<00:07,  3.55it/s]\u001b[A\n","Iteration:  83% 116/140 [00:49<00:06,  3.53it/s]\u001b[A\n","Iteration:  84% 117/140 [00:49<00:06,  3.53it/s]\u001b[A\n","Iteration:  84% 118/140 [00:49<00:06,  3.52it/s]\u001b[A\n","Iteration:  85% 119/140 [00:50<00:05,  3.53it/s]\u001b[A\n","Iteration:  86% 120/140 [00:50<00:05,  3.54it/s]\u001b[A\n","Iteration:  86% 121/140 [00:50<00:05,  3.54it/s]\u001b[A\n","Iteration:  87% 122/140 [00:51<00:05,  3.52it/s]\u001b[A\n","Iteration:  88% 123/140 [00:51<00:04,  3.52it/s]\u001b[A\n","Iteration:  89% 124/140 [00:51<00:04,  3.52it/s]\u001b[A\n","Iteration:  89% 125/140 [00:51<00:04,  3.50it/s]\u001b[A\n","Iteration:  90% 126/140 [00:52<00:04,  3.48it/s]\u001b[A\n","Iteration:  91% 127/140 [00:52<00:03,  3.48it/s]\u001b[A\n","Iteration:  91% 128/140 [00:52<00:03,  3.48it/s]\u001b[A\n","Iteration:  92% 129/140 [00:53<00:03,  3.48it/s]\u001b[A\n","Iteration:  93% 130/140 [00:53<00:02,  3.49it/s]\u001b[A\n","Iteration:  94% 131/140 [00:53<00:02,  3.47it/s]\u001b[A\n","Iteration:  94% 132/140 [00:53<00:02,  3.46it/s]\u001b[A\n","Iteration:  95% 133/140 [00:54<00:02,  3.49it/s]\u001b[A\n","Iteration:  96% 134/140 [00:54<00:01,  3.48it/s]\u001b[A\n","Iteration:  96% 135/140 [00:54<00:01,  3.48it/s]\u001b[A\n","Iteration:  97% 136/140 [00:55<00:01,  3.49it/s]\u001b[A\n","Iteration:  98% 137/140 [00:55<00:00,  3.49it/s]\u001b[A\n","Iteration:  99% 138/140 [00:55<00:00,  3.48it/s]\u001b[A\n","Iteration:  99% 139/140 [00:55<00:00,  3.47it/s]\u001b[A\n","Iteration: 100% 140/140 [00:56<00:00,  2.49it/s]\n","Epoch:  20% 2/10 [01:34<06:30, 48.86s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:40,  3.46it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:39,  3.47it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:39,  3.48it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:39,  3.45it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:38,  3.47it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:38,  3.49it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:38,  3.49it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:37,  3.50it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:37,  3.51it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:37,  3.50it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:36,  3.51it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:36,  3.52it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:36,  3.52it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:35,  3.50it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:35,  3.50it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:35,  3.50it/s]\u001b[A\n","Iteration:  12% 17/140 [00:04<00:35,  3.51it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:34,  3.51it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:34,  3.51it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:34,  3.51it/s]\u001b[A\n","Iteration:  15% 21/140 [00:05<00:33,  3.51it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:33,  3.51it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:33,  3.51it/s]\u001b[A\n","Iteration:  17% 24/140 [00:06<00:33,  3.50it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:32,  3.51it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:32,  3.50it/s]\u001b[A\n","Iteration:  19% 27/140 [00:07<00:32,  3.51it/s]\u001b[A\n","Iteration:  20% 28/140 [00:07<00:32,  3.50it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:31,  3.50it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:31,  3.51it/s]\u001b[A\n","Iteration:  22% 31/140 [00:08<00:31,  3.49it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:30,  3.49it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:30,  3.50it/s]\u001b[A\n","Iteration:  24% 34/140 [00:09<00:30,  3.49it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:30,  3.48it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:29,  3.48it/s]\u001b[A\n","Iteration:  26% 37/140 [00:10<00:29,  3.47it/s]\u001b[A\n","Iteration:  27% 38/140 [00:10<00:29,  3.48it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:28,  3.48it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:28,  3.48it/s]\u001b[A\n","Iteration:  29% 41/140 [00:11<00:28,  3.49it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:28,  3.47it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:27,  3.48it/s]\u001b[A\n","Iteration:  31% 44/140 [00:12<00:27,  3.48it/s]\u001b[A\n","Iteration:  32% 45/140 [00:12<00:27,  3.48it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:27,  3.48it/s]\u001b[A\n","Iteration:  34% 47/140 [00:13<00:26,  3.52it/s]\u001b[A\n","Iteration:  34% 48/140 [00:13<00:26,  3.47it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:26,  3.46it/s]\u001b[A\n","Iteration:  36% 50/140 [00:14<00:26,  3.44it/s]\u001b[A\n","Iteration:  36% 51/140 [00:14<00:25,  3.45it/s]\u001b[A\n","Iteration:  37% 52/140 [00:14<00:25,  3.46it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:25,  3.47it/s]\u001b[A\n","Iteration:  39% 54/140 [00:15<00:24,  3.47it/s]\u001b[A\n","Iteration:  39% 55/140 [00:15<00:24,  3.46it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:24,  3.47it/s]\u001b[A\n","Iteration:  41% 57/140 [00:16<00:23,  3.48it/s]\u001b[A\n","Iteration:  41% 58/140 [00:16<00:23,  3.47it/s]\u001b[A\n","Iteration:  42% 59/140 [00:16<00:23,  3.46it/s]\u001b[A\n","Iteration:  43% 60/140 [00:17<00:23,  3.46it/s]\u001b[A\n","Iteration:  44% 61/140 [00:17<00:22,  3.46it/s]\u001b[A\n","Iteration:  44% 62/140 [00:17<00:22,  3.46it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:22,  3.47it/s]\u001b[A\n","Iteration:  46% 64/140 [00:18<00:21,  3.47it/s]\u001b[A\n","Iteration:  46% 65/140 [00:18<00:21,  3.46it/s]\u001b[A\n","Iteration:  47% 66/140 [00:18<00:21,  3.46it/s]\u001b[A\n","Iteration:  48% 67/140 [00:19<00:21,  3.45it/s]\u001b[A\n","Iteration:  49% 68/140 [00:19<00:20,  3.46it/s]\u001b[A\n","Iteration:  49% 69/140 [00:19<00:20,  3.46it/s]\u001b[A\n","Iteration:  50% 70/140 [00:20<00:20,  3.46it/s]\u001b[A\n","Iteration:  51% 71/140 [00:20<00:19,  3.46it/s]\u001b[A\n","Iteration:  51% 72/140 [00:20<00:19,  3.46it/s]\u001b[A\n","Iteration:  52% 73/140 [00:20<00:19,  3.46it/s]\u001b[A\n","Iteration:  53% 74/140 [00:21<00:19,  3.46it/s]\u001b[A\n","Iteration:  54% 75/140 [00:21<00:18,  3.44it/s]\u001b[A\n","Iteration:  54% 76/140 [00:21<00:18,  3.45it/s]\u001b[A\n","Iteration:  55% 77/140 [00:22<00:18,  3.46it/s]\u001b[A\n","Iteration:  56% 78/140 [00:22<00:17,  3.46it/s]\u001b[A\n","Iteration:  56% 79/140 [00:22<00:17,  3.45it/s]\u001b[A\n","Iteration:  57% 80/140 [00:22<00:17,  3.46it/s]\u001b[A\n","Iteration:  58% 81/140 [00:23<00:17,  3.46it/s]\u001b[A\n","Iteration:  59% 82/140 [00:23<00:16,  3.46it/s]\u001b[A\n","Iteration:  59% 83/140 [00:23<00:16,  3.46it/s]\u001b[A\n","Iteration:  60% 84/140 [00:24<00:16,  3.45it/s]\u001b[A\n","Iteration:  61% 85/140 [00:24<00:15,  3.46it/s]\u001b[A\n","Iteration:  61% 86/140 [00:24<00:15,  3.45it/s]\u001b[A\n","Iteration:  62% 87/140 [00:25<00:15,  3.45it/s]\u001b[A\n","Iteration:  63% 88/140 [00:25<00:15,  3.45it/s]\u001b[A\n","Iteration:  64% 89/140 [00:25<00:14,  3.45it/s]\u001b[A\n","Iteration:  64% 90/140 [00:25<00:14,  3.45it/s]\u001b[A\n","Iteration:  65% 91/140 [00:26<00:14,  3.47it/s]\u001b[A\n","Iteration:  66% 92/140 [00:26<00:13,  3.45it/s]\u001b[A\n","Iteration:  66% 93/140 [00:26<00:13,  3.46it/s]\u001b[A\n","Iteration:  67% 94/140 [00:27<00:13,  3.46it/s]\u001b[A\n","Iteration:  68% 95/140 [00:27<00:13,  3.45it/s]\u001b[A\n","Iteration:  69% 96/140 [00:27<00:12,  3.47it/s]\u001b[A\n","Iteration:  69% 97/140 [00:27<00:12,  3.47it/s]\u001b[A\n","Iteration:  70% 98/140 [00:28<00:12,  3.48it/s]\u001b[A\n","Iteration:  71% 99/140 [00:28<00:11,  3.45it/s]\u001b[A\n","Iteration:  71% 100/140 [00:28<00:11,  3.44it/s]\u001b[A\n","Iteration:  72% 101/140 [00:29<00:11,  3.43it/s]\u001b[A\n","Iteration:  73% 102/140 [00:29<00:11,  3.41it/s]\u001b[A\n","Iteration:  74% 103/140 [00:29<00:10,  3.43it/s]\u001b[A\n","Iteration:  74% 104/140 [00:29<00:10,  3.44it/s]\u001b[A\n","Iteration:  75% 105/140 [00:30<00:10,  3.44it/s]\u001b[A\n","Iteration:  76% 106/140 [00:30<00:09,  3.44it/s]\u001b[A\n","Iteration:  76% 107/140 [00:30<00:09,  3.46it/s]\u001b[A\n","Iteration:  77% 108/140 [00:31<00:09,  3.46it/s]\u001b[A\n","Iteration:  78% 109/140 [00:31<00:08,  3.45it/s]\u001b[A\n","Iteration:  79% 110/140 [00:31<00:08,  3.44it/s]\u001b[A\n","Iteration:  79% 111/140 [00:31<00:08,  3.45it/s]\u001b[A\n","Iteration:  80% 112/140 [00:32<00:08,  3.44it/s]\u001b[A\n","Iteration:  81% 113/140 [00:32<00:07,  3.44it/s]\u001b[A\n","Iteration:  81% 114/140 [00:32<00:07,  3.45it/s]\u001b[A\n","Iteration:  82% 115/140 [00:33<00:07,  3.45it/s]\u001b[A\n","Iteration:  83% 116/140 [00:33<00:07,  3.42it/s]\u001b[A\n","Iteration:  84% 117/140 [00:33<00:06,  3.43it/s]\u001b[A\n","Iteration:  84% 118/140 [00:34<00:06,  3.43it/s]\u001b[A\n","Iteration:  85% 119/140 [00:34<00:06,  3.43it/s]\u001b[A03/04/2022 01:34:09 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:34:09 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:34:09 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  6.11it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.84it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.89it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.84it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.86it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.86it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.88it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.99it/s]\n","03/04/2022 01:34:11 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:34:11 - INFO - trainer -     intent_acc = 0.974\n","03/04/2022 01:34:11 - INFO - trainer -     loss = 0.2526544816792011\n","03/04/2022 01:34:11 - INFO - trainer -     sementic_frame_acc = 0.834\n","03/04/2022 01:34:11 - INFO - trainer -     slot_f1 = 0.9393323657474602\n","03/04/2022 01:34:11 - INFO - trainer -     slot_precision = 0.9325648414985591\n","03/04/2022 01:34:11 - INFO - trainer -     slot_recall = 0.9461988304093567\n","03/04/2022 01:34:11 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:34:15 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:34:15 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  86% 120/140 [00:40<00:39,  1.96s/it]\u001b[A\n","Iteration:  86% 121/140 [00:40<00:28,  1.48s/it]\u001b[A\n","Iteration:  87% 122/140 [00:40<00:20,  1.12s/it]\u001b[A\n","Iteration:  88% 123/140 [00:41<00:14,  1.14it/s]\u001b[A\n","Iteration:  89% 124/140 [00:41<00:11,  1.43it/s]\u001b[A\n","Iteration:  89% 125/140 [00:41<00:08,  1.73it/s]\u001b[A\n","Iteration:  90% 126/140 [00:41<00:06,  2.04it/s]\u001b[A\n","Iteration:  91% 127/140 [00:42<00:05,  2.32it/s]\u001b[A\n","Iteration:  91% 128/140 [00:42<00:04,  2.56it/s]\u001b[A\n","Iteration:  92% 129/140 [00:42<00:03,  2.77it/s]\u001b[A\n","Iteration:  93% 130/140 [00:43<00:03,  2.94it/s]\u001b[A\n","Iteration:  94% 131/140 [00:43<00:02,  3.08it/s]\u001b[A\n","Iteration:  94% 132/140 [00:43<00:02,  3.17it/s]\u001b[A\n","Iteration:  95% 133/140 [00:44<00:02,  3.24it/s]\u001b[A\n","Iteration:  96% 134/140 [00:44<00:01,  3.30it/s]\u001b[A\n","Iteration:  96% 135/140 [00:44<00:01,  3.32it/s]\u001b[A\n","Iteration:  97% 136/140 [00:44<00:01,  3.36it/s]\u001b[A\n","Iteration:  98% 137/140 [00:45<00:00,  3.38it/s]\u001b[A\n","Iteration:  99% 138/140 [00:45<00:00,  3.39it/s]\u001b[A\n","Iteration:  99% 139/140 [00:45<00:00,  3.40it/s]\u001b[A\n","Iteration: 100% 140/140 [00:46<00:00,  3.04it/s]\n","Epoch:  30% 3/10 [02:20<05:33, 47.58s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:41,  3.37it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:41,  3.34it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:41,  3.34it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:40,  3.37it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:39,  3.39it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:39,  3.35it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:39,  3.36it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:39,  3.34it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:38,  3.40it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:38,  3.36it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.35it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:38,  3.35it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:37,  3.35it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.36it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.33it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:37,  3.34it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:36,  3.35it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.35it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:36,  3.36it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:35,  3.37it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.35it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:35,  3.34it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:35,  3.33it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:34,  3.32it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:34,  3.34it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:34,  3.33it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.34it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:33,  3.32it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:33,  3.31it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:33,  3.33it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.35it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:32,  3.34it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:32,  3.31it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:32,  3.30it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.32it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:31,  3.32it/s]\u001b[A\n","Iteration:  26% 37/140 [00:11<00:30,  3.33it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.32it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.29it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:30,  3.31it/s]\u001b[A\n","Iteration:  29% 41/140 [00:12<00:29,  3.30it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:29,  3.31it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:29,  3.30it/s]\u001b[A\n","Iteration:  31% 44/140 [00:13<00:28,  3.32it/s]\u001b[A\n","Iteration:  32% 45/140 [00:13<00:28,  3.32it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:28,  3.33it/s]\u001b[A\n","Iteration:  34% 47/140 [00:14<00:27,  3.34it/s]\u001b[A\n","Iteration:  34% 48/140 [00:14<00:27,  3.33it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:27,  3.33it/s]\u001b[A\n","Iteration:  36% 50/140 [00:14<00:27,  3.32it/s]\u001b[A\n","Iteration:  36% 51/140 [00:15<00:26,  3.32it/s]\u001b[A\n","Iteration:  37% 52/140 [00:15<00:26,  3.33it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:26,  3.33it/s]\u001b[A\n","Iteration:  39% 54/140 [00:16<00:25,  3.36it/s]\u001b[A\n","Iteration:  39% 55/140 [00:16<00:25,  3.36it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:24,  3.37it/s]\u001b[A\n","Iteration:  41% 57/140 [00:17<00:24,  3.39it/s]\u001b[A\n","Iteration:  41% 58/140 [00:17<00:24,  3.38it/s]\u001b[A\n","Iteration:  42% 59/140 [00:17<00:23,  3.40it/s]\u001b[A\n","Iteration:  43% 60/140 [00:17<00:23,  3.38it/s]\u001b[A\n","Iteration:  44% 61/140 [00:18<00:23,  3.39it/s]\u001b[A\n","Iteration:  44% 62/140 [00:18<00:23,  3.39it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:22,  3.38it/s]\u001b[A\n","Iteration:  46% 64/140 [00:19<00:22,  3.38it/s]\u001b[A\n","Iteration:  46% 65/140 [00:19<00:22,  3.38it/s]\u001b[A\n","Iteration:  47% 66/140 [00:19<00:21,  3.37it/s]\u001b[A\n","Iteration:  48% 67/140 [00:20<00:21,  3.37it/s]\u001b[A\n","Iteration:  49% 68/140 [00:20<00:21,  3.36it/s]\u001b[A\n","Iteration:  49% 69/140 [00:20<00:21,  3.36it/s]\u001b[A\n","Iteration:  50% 70/140 [00:20<00:20,  3.35it/s]\u001b[A\n","Iteration:  51% 71/140 [00:21<00:20,  3.34it/s]\u001b[A\n","Iteration:  51% 72/140 [00:21<00:20,  3.34it/s]\u001b[A\n","Iteration:  52% 73/140 [00:21<00:20,  3.35it/s]\u001b[A\n","Iteration:  53% 74/140 [00:22<00:19,  3.37it/s]\u001b[A\n","Iteration:  54% 75/140 [00:22<00:19,  3.38it/s]\u001b[A\n","Iteration:  54% 76/140 [00:22<00:18,  3.38it/s]\u001b[A\n","Iteration:  55% 77/140 [00:23<00:18,  3.38it/s]\u001b[A\n","Iteration:  56% 78/140 [00:23<00:18,  3.38it/s]\u001b[A\n","Iteration:  56% 79/140 [00:23<00:18,  3.37it/s]\u001b[A\n","Iteration:  57% 80/140 [00:23<00:17,  3.38it/s]\u001b[A\n","Iteration:  58% 81/140 [00:24<00:17,  3.37it/s]\u001b[A\n","Iteration:  59% 82/140 [00:24<00:17,  3.38it/s]\u001b[A\n","Iteration:  59% 83/140 [00:24<00:16,  3.38it/s]\u001b[A\n","Iteration:  60% 84/140 [00:25<00:16,  3.37it/s]\u001b[A\n","Iteration:  61% 85/140 [00:25<00:16,  3.37it/s]\u001b[A\n","Iteration:  61% 86/140 [00:25<00:15,  3.38it/s]\u001b[A\n","Iteration:  62% 87/140 [00:25<00:15,  3.38it/s]\u001b[A\n","Iteration:  63% 88/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 89/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 90/140 [00:26<00:14,  3.37it/s]\u001b[A\n","Iteration:  65% 91/140 [00:27<00:14,  3.36it/s]\u001b[A\n","Iteration:  66% 92/140 [00:27<00:14,  3.36it/s]\u001b[A\n","Iteration:  66% 93/140 [00:27<00:14,  3.35it/s]\u001b[A\n","Iteration:  67% 94/140 [00:28<00:13,  3.36it/s]\u001b[A\n","Iteration:  68% 95/140 [00:28<00:13,  3.37it/s]\u001b[A\n","Iteration:  69% 96/140 [00:28<00:13,  3.36it/s]\u001b[A\n","Iteration:  69% 97/140 [00:28<00:12,  3.38it/s]\u001b[A\n","Iteration:  70% 98/140 [00:29<00:12,  3.37it/s]\u001b[A\n","Iteration:  71% 99/140 [00:29<00:12,  3.36it/s]\u001b[A\n","Iteration:  71% 100/140 [00:29<00:11,  3.36it/s]\u001b[A\n","Iteration:  72% 101/140 [00:30<00:11,  3.37it/s]\u001b[A\n","Iteration:  73% 102/140 [00:30<00:11,  3.36it/s]\u001b[A\n","Iteration:  74% 103/140 [00:30<00:11,  3.36it/s]\u001b[A\n","Iteration:  74% 104/140 [00:31<00:10,  3.35it/s]\u001b[A\n","Iteration:  75% 105/140 [00:31<00:10,  3.35it/s]\u001b[A\n","Iteration:  76% 106/140 [00:31<00:10,  3.36it/s]\u001b[A\n","Iteration:  76% 107/140 [00:31<00:09,  3.36it/s]\u001b[A\n","Iteration:  77% 108/140 [00:32<00:09,  3.36it/s]\u001b[A\n","Iteration:  78% 109/140 [00:32<00:09,  3.36it/s]\u001b[A\n","Iteration:  79% 110/140 [00:32<00:08,  3.37it/s]\u001b[A\n","Iteration:  79% 111/140 [00:33<00:08,  3.37it/s]\u001b[A\n","Iteration:  80% 112/140 [00:33<00:08,  3.37it/s]\u001b[A\n","Iteration:  81% 113/140 [00:33<00:08,  3.36it/s]\u001b[A\n","Iteration:  81% 114/140 [00:33<00:07,  3.38it/s]\u001b[A\n","Iteration:  82% 115/140 [00:34<00:07,  3.37it/s]\u001b[A\n","Iteration:  83% 116/140 [00:34<00:07,  3.35it/s]\u001b[A\n","Iteration:  84% 117/140 [00:34<00:06,  3.35it/s]\u001b[A\n","Iteration:  84% 118/140 [00:35<00:06,  3.35it/s]\u001b[A\n","Iteration:  85% 119/140 [00:35<00:06,  3.35it/s]\u001b[A\n","Iteration:  86% 120/140 [00:35<00:06,  3.33it/s]\u001b[A\n","Iteration:  86% 121/140 [00:36<00:05,  3.32it/s]\u001b[A\n","Iteration:  87% 122/140 [00:36<00:05,  3.33it/s]\u001b[A\n","Iteration:  88% 123/140 [00:36<00:05,  3.33it/s]\u001b[A\n","Iteration:  89% 124/140 [00:36<00:04,  3.33it/s]\u001b[A\n","Iteration:  89% 125/140 [00:37<00:04,  3.32it/s]\u001b[A\n","Iteration:  90% 126/140 [00:37<00:04,  3.32it/s]\u001b[A\n","Iteration:  91% 127/140 [00:37<00:03,  3.31it/s]\u001b[A\n","Iteration:  91% 128/140 [00:38<00:03,  3.31it/s]\u001b[A\n","Iteration:  92% 129/140 [00:38<00:03,  3.34it/s]\u001b[A\n","Iteration:  93% 130/140 [00:38<00:03,  3.33it/s]\u001b[A\n","Iteration:  94% 131/140 [00:39<00:02,  3.32it/s]\u001b[A\n","Iteration:  94% 132/140 [00:39<00:02,  3.31it/s]\u001b[A\n","Iteration:  95% 133/140 [00:39<00:02,  3.31it/s]\u001b[A\n","Iteration:  96% 134/140 [00:40<00:01,  3.32it/s]\u001b[A\n","Iteration:  96% 135/140 [00:40<00:01,  3.32it/s]\u001b[A\n","Iteration:  97% 136/140 [00:40<00:01,  3.34it/s]\u001b[A\n","Iteration:  98% 137/140 [00:40<00:00,  3.31it/s]\u001b[A\n","Iteration:  99% 138/140 [00:41<00:00,  3.31it/s]\u001b[A\n","Iteration:  99% 139/140 [00:41<00:00,  3.31it/s]\u001b[A\n","Iteration: 100% 140/140 [00:41<00:00,  3.35it/s]\n","Epoch:  40% 4/10 [03:02<04:31, 45.30s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:42,  3.30it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:41,  3.30it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:41,  3.30it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:41,  3.31it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:40,  3.31it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:40,  3.31it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:40,  3.31it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:40,  3.29it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:39,  3.30it/s]\u001b[A\n","Iteration:   7% 10/140 [00:03<00:39,  3.30it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.33it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:38,  3.30it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:38,  3.31it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:38,  3.31it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.31it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:37,  3.31it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:37,  3.32it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.32it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:36,  3.33it/s]\u001b[A\n","Iteration:  14% 20/140 [00:06<00:35,  3.34it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.34it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:35,  3.32it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:35,  3.32it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:35,  3.31it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:34,  3.30it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:34,  3.30it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.33it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:33,  3.32it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:33,  3.33it/s]\u001b[A\n","Iteration:  21% 30/140 [00:09<00:33,  3.33it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.33it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:32,  3.32it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:32,  3.33it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:31,  3.32it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.32it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:31,  3.35it/s]\u001b[A\n","Iteration:  26% 37/140 [00:11<00:30,  3.34it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.34it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.35it/s]\u001b[A03/04/2022 01:35:15 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:35:15 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:35:15 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  5.97it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.62it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.64it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.58it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.59it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.64it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.64it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.76it/s]\n","03/04/2022 01:35:16 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:35:16 - INFO - trainer -     intent_acc = 0.978\n","03/04/2022 01:35:16 - INFO - trainer -     loss = 0.21710247872397304\n","03/04/2022 01:35:16 - INFO - trainer -     sementic_frame_acc = 0.88\n","03/04/2022 01:35:16 - INFO - trainer -     slot_f1 = 0.9615384615384616\n","03/04/2022 01:35:16 - INFO - trainer -     slot_precision = 0.9581881533101045\n","03/04/2022 01:35:16 - INFO - trainer -     slot_recall = 0.9649122807017544\n","03/04/2022 01:35:16 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:35:20 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:35:21 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  29% 40/140 [00:18<03:34,  2.15s/it]\u001b[A\n","Iteration:  29% 41/140 [00:18<02:39,  1.61s/it]\u001b[A\n","Iteration:  30% 42/140 [00:18<01:59,  1.22s/it]\u001b[A\n","Iteration:  31% 43/140 [00:19<01:31,  1.06it/s]\u001b[A\n","Iteration:  31% 44/140 [00:19<01:11,  1.34it/s]\u001b[A\n","Iteration:  32% 45/140 [00:19<00:58,  1.64it/s]\u001b[A\n","Iteration:  33% 46/140 [00:20<00:48,  1.93it/s]\u001b[A\n","Iteration:  34% 47/140 [00:20<00:41,  2.22it/s]\u001b[A\n","Iteration:  34% 48/140 [00:20<00:37,  2.47it/s]\u001b[A\n","Iteration:  35% 49/140 [00:20<00:33,  2.70it/s]\u001b[A\n","Iteration:  36% 50/140 [00:21<00:31,  2.87it/s]\u001b[A\n","Iteration:  36% 51/140 [00:21<00:29,  3.01it/s]\u001b[A\n","Iteration:  37% 52/140 [00:21<00:28,  3.12it/s]\u001b[A\n","Iteration:  38% 53/140 [00:22<00:27,  3.19it/s]\u001b[A\n","Iteration:  39% 54/140 [00:22<00:26,  3.24it/s]\u001b[A\n","Iteration:  39% 55/140 [00:22<00:25,  3.27it/s]\u001b[A\n","Iteration:  40% 56/140 [00:23<00:25,  3.29it/s]\u001b[A\n","Iteration:  41% 57/140 [00:23<00:24,  3.33it/s]\u001b[A\n","Iteration:  41% 58/140 [00:23<00:24,  3.29it/s]\u001b[A\n","Iteration:  42% 59/140 [00:23<00:24,  3.29it/s]\u001b[A\n","Iteration:  43% 60/140 [00:24<00:24,  3.30it/s]\u001b[A\n","Iteration:  44% 61/140 [00:24<00:23,  3.30it/s]\u001b[A\n","Iteration:  44% 62/140 [00:24<00:23,  3.30it/s]\u001b[A\n","Iteration:  45% 63/140 [00:25<00:23,  3.31it/s]\u001b[A\n","Iteration:  46% 64/140 [00:25<00:23,  3.30it/s]\u001b[A\n","Iteration:  46% 65/140 [00:25<00:22,  3.31it/s]\u001b[A\n","Iteration:  47% 66/140 [00:26<00:22,  3.33it/s]\u001b[A\n","Iteration:  48% 67/140 [00:26<00:21,  3.34it/s]\u001b[A\n","Iteration:  49% 68/140 [00:26<00:21,  3.34it/s]\u001b[A\n","Iteration:  49% 69/140 [00:26<00:21,  3.32it/s]\u001b[A\n","Iteration:  50% 70/140 [00:27<00:21,  3.31it/s]\u001b[A\n","Iteration:  51% 71/140 [00:27<00:20,  3.32it/s]\u001b[A\n","Iteration:  51% 72/140 [00:27<00:20,  3.32it/s]\u001b[A\n","Iteration:  52% 73/140 [00:28<00:20,  3.34it/s]\u001b[A\n","Iteration:  53% 74/140 [00:28<00:19,  3.35it/s]\u001b[A\n","Iteration:  54% 75/140 [00:28<00:19,  3.35it/s]\u001b[A\n","Iteration:  54% 76/140 [00:29<00:19,  3.34it/s]\u001b[A\n","Iteration:  55% 77/140 [00:29<00:18,  3.32it/s]\u001b[A\n","Iteration:  56% 78/140 [00:29<00:18,  3.30it/s]\u001b[A\n","Iteration:  56% 79/140 [00:29<00:18,  3.31it/s]\u001b[A\n","Iteration:  57% 80/140 [00:30<00:18,  3.29it/s]\u001b[A\n","Iteration:  58% 81/140 [00:30<00:17,  3.30it/s]\u001b[A\n","Iteration:  59% 82/140 [00:30<00:17,  3.30it/s]\u001b[A\n","Iteration:  59% 83/140 [00:31<00:17,  3.30it/s]\u001b[A\n","Iteration:  60% 84/140 [00:31<00:16,  3.32it/s]\u001b[A\n","Iteration:  61% 85/140 [00:31<00:16,  3.31it/s]\u001b[A\n","Iteration:  61% 86/140 [00:32<00:16,  3.33it/s]\u001b[A\n","Iteration:  62% 87/140 [00:32<00:15,  3.32it/s]\u001b[A\n","Iteration:  63% 88/140 [00:32<00:15,  3.31it/s]\u001b[A\n","Iteration:  64% 89/140 [00:32<00:15,  3.32it/s]\u001b[A\n","Iteration:  64% 90/140 [00:33<00:15,  3.33it/s]\u001b[A\n","Iteration:  65% 91/140 [00:33<00:14,  3.34it/s]\u001b[A\n","Iteration:  66% 92/140 [00:33<00:14,  3.32it/s]\u001b[A\n","Iteration:  66% 93/140 [00:34<00:14,  3.32it/s]\u001b[A\n","Iteration:  67% 94/140 [00:34<00:13,  3.31it/s]\u001b[A\n","Iteration:  68% 95/140 [00:34<00:13,  3.31it/s]\u001b[A\n","Iteration:  69% 96/140 [00:35<00:13,  3.32it/s]\u001b[A\n","Iteration:  69% 97/140 [00:35<00:12,  3.32it/s]\u001b[A\n","Iteration:  70% 98/140 [00:35<00:12,  3.29it/s]\u001b[A\n","Iteration:  71% 99/140 [00:35<00:12,  3.30it/s]\u001b[A\n","Iteration:  71% 100/140 [00:36<00:12,  3.29it/s]\u001b[A\n","Iteration:  72% 101/140 [00:36<00:11,  3.30it/s]\u001b[A\n","Iteration:  73% 102/140 [00:36<00:11,  3.30it/s]\u001b[A\n","Iteration:  74% 103/140 [00:37<00:11,  3.31it/s]\u001b[A\n","Iteration:  74% 104/140 [00:37<00:10,  3.29it/s]\u001b[A\n","Iteration:  75% 105/140 [00:37<00:10,  3.30it/s]\u001b[A\n","Iteration:  76% 106/140 [00:38<00:10,  3.29it/s]\u001b[A\n","Iteration:  76% 107/140 [00:38<00:09,  3.30it/s]\u001b[A\n","Iteration:  77% 108/140 [00:38<00:09,  3.31it/s]\u001b[A\n","Iteration:  78% 109/140 [00:38<00:09,  3.32it/s]\u001b[A\n","Iteration:  79% 110/140 [00:39<00:08,  3.33it/s]\u001b[A\n","Iteration:  79% 111/140 [00:39<00:08,  3.33it/s]\u001b[A\n","Iteration:  80% 112/140 [00:39<00:08,  3.35it/s]\u001b[A\n","Iteration:  81% 113/140 [00:40<00:08,  3.34it/s]\u001b[A\n","Iteration:  81% 114/140 [00:40<00:07,  3.33it/s]\u001b[A\n","Iteration:  82% 115/140 [00:40<00:07,  3.32it/s]\u001b[A\n","Iteration:  83% 116/140 [00:41<00:07,  3.31it/s]\u001b[A\n","Iteration:  84% 117/140 [00:41<00:06,  3.31it/s]\u001b[A\n","Iteration:  84% 118/140 [00:41<00:06,  3.31it/s]\u001b[A\n","Iteration:  85% 119/140 [00:42<00:06,  3.31it/s]\u001b[A\n","Iteration:  86% 120/140 [00:42<00:06,  3.31it/s]\u001b[A\n","Iteration:  86% 121/140 [00:42<00:05,  3.31it/s]\u001b[A\n","Iteration:  87% 122/140 [00:42<00:05,  3.31it/s]\u001b[A\n","Iteration:  88% 123/140 [00:43<00:05,  3.33it/s]\u001b[A\n","Iteration:  89% 124/140 [00:43<00:04,  3.32it/s]\u001b[A\n","Iteration:  89% 125/140 [00:43<00:04,  3.33it/s]\u001b[A\n","Iteration:  90% 126/140 [00:44<00:04,  3.32it/s]\u001b[A\n","Iteration:  91% 127/140 [00:44<00:03,  3.32it/s]\u001b[A\n","Iteration:  91% 128/140 [00:44<00:03,  3.32it/s]\u001b[A\n","Iteration:  92% 129/140 [00:45<00:03,  3.31it/s]\u001b[A\n","Iteration:  93% 130/140 [00:45<00:03,  3.31it/s]\u001b[A\n","Iteration:  94% 131/140 [00:45<00:02,  3.30it/s]\u001b[A\n","Iteration:  94% 132/140 [00:45<00:02,  3.31it/s]\u001b[A\n","Iteration:  95% 133/140 [00:46<00:02,  3.32it/s]\u001b[A\n","Iteration:  96% 134/140 [00:46<00:01,  3.34it/s]\u001b[A\n","Iteration:  96% 135/140 [00:46<00:01,  3.33it/s]\u001b[A\n","Iteration:  97% 136/140 [00:47<00:01,  3.34it/s]\u001b[A\n","Iteration:  98% 137/140 [00:47<00:00,  3.34it/s]\u001b[A\n","Iteration:  99% 138/140 [00:47<00:00,  3.32it/s]\u001b[A\n","Iteration:  99% 139/140 [00:48<00:00,  3.32it/s]\u001b[A\n","Iteration: 100% 140/140 [00:48<00:00,  2.90it/s]\n","Epoch:  50% 5/10 [03:50<03:51, 46.39s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:41,  3.36it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:40,  3.37it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:40,  3.36it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:40,  3.35it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:40,  3.36it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:39,  3.37it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:39,  3.38it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:39,  3.36it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:39,  3.35it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:38,  3.35it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.36it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:38,  3.36it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:37,  3.38it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.37it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.37it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:36,  3.38it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:36,  3.37it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.38it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:35,  3.38it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:35,  3.37it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.37it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:34,  3.37it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:34,  3.36it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:34,  3.37it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:34,  3.38it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:33,  3.38it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.37it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:33,  3.37it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:32,  3.37it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:32,  3.36it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.37it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:31,  3.39it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:31,  3.39it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:31,  3.39it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.36it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:30,  3.37it/s]\u001b[A\n","Iteration:  26% 37/140 [00:10<00:30,  3.36it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.36it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.36it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:29,  3.34it/s]\u001b[A\n","Iteration:  29% 41/140 [00:12<00:29,  3.34it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:29,  3.33it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:29,  3.34it/s]\u001b[A\n","Iteration:  31% 44/140 [00:13<00:28,  3.34it/s]\u001b[A\n","Iteration:  32% 45/140 [00:13<00:28,  3.34it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:28,  3.35it/s]\u001b[A\n","Iteration:  34% 47/140 [00:13<00:27,  3.35it/s]\u001b[A\n","Iteration:  34% 48/140 [00:14<00:27,  3.35it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:27,  3.34it/s]\u001b[A\n","Iteration:  36% 50/140 [00:14<00:26,  3.34it/s]\u001b[A\n","Iteration:  36% 51/140 [00:15<00:26,  3.34it/s]\u001b[A\n","Iteration:  37% 52/140 [00:15<00:26,  3.32it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:26,  3.34it/s]\u001b[A\n","Iteration:  39% 54/140 [00:16<00:25,  3.35it/s]\u001b[A\n","Iteration:  39% 55/140 [00:16<00:25,  3.34it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:24,  3.36it/s]\u001b[A\n","Iteration:  41% 57/140 [00:16<00:24,  3.36it/s]\u001b[A\n","Iteration:  41% 58/140 [00:17<00:24,  3.38it/s]\u001b[A\n","Iteration:  42% 59/140 [00:17<00:24,  3.37it/s]\u001b[A\n","Iteration:  43% 60/140 [00:17<00:23,  3.37it/s]\u001b[A\n","Iteration:  44% 61/140 [00:18<00:23,  3.38it/s]\u001b[A\n","Iteration:  44% 62/140 [00:18<00:23,  3.39it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:22,  3.37it/s]\u001b[A\n","Iteration:  46% 64/140 [00:19<00:22,  3.38it/s]\u001b[A\n","Iteration:  46% 65/140 [00:19<00:22,  3.38it/s]\u001b[A\n","Iteration:  47% 66/140 [00:19<00:21,  3.37it/s]\u001b[A\n","Iteration:  48% 67/140 [00:19<00:21,  3.36it/s]\u001b[A\n","Iteration:  49% 68/140 [00:20<00:21,  3.38it/s]\u001b[A\n","Iteration:  49% 69/140 [00:20<00:21,  3.36it/s]\u001b[A\n","Iteration:  50% 70/140 [00:20<00:20,  3.37it/s]\u001b[A\n","Iteration:  51% 71/140 [00:21<00:20,  3.36it/s]\u001b[A\n","Iteration:  51% 72/140 [00:21<00:20,  3.37it/s]\u001b[A\n","Iteration:  52% 73/140 [00:21<00:19,  3.38it/s]\u001b[A\n","Iteration:  53% 74/140 [00:21<00:19,  3.38it/s]\u001b[A\n","Iteration:  54% 75/140 [00:22<00:19,  3.36it/s]\u001b[A\n","Iteration:  54% 76/140 [00:22<00:18,  3.37it/s]\u001b[A\n","Iteration:  55% 77/140 [00:22<00:18,  3.36it/s]\u001b[A\n","Iteration:  56% 78/140 [00:23<00:18,  3.36it/s]\u001b[A\n","Iteration:  56% 79/140 [00:23<00:18,  3.37it/s]\u001b[A\n","Iteration:  57% 80/140 [00:23<00:18,  3.32it/s]\u001b[A\n","Iteration:  58% 81/140 [00:24<00:17,  3.34it/s]\u001b[A\n","Iteration:  59% 82/140 [00:24<00:17,  3.34it/s]\u001b[A\n","Iteration:  59% 83/140 [00:24<00:16,  3.35it/s]\u001b[A\n","Iteration:  60% 84/140 [00:24<00:16,  3.35it/s]\u001b[A\n","Iteration:  61% 85/140 [00:25<00:16,  3.37it/s]\u001b[A\n","Iteration:  61% 86/140 [00:25<00:16,  3.36it/s]\u001b[A\n","Iteration:  62% 87/140 [00:25<00:15,  3.36it/s]\u001b[A\n","Iteration:  63% 88/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 89/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 90/140 [00:26<00:14,  3.38it/s]\u001b[A\n","Iteration:  65% 91/140 [00:27<00:14,  3.37it/s]\u001b[A\n","Iteration:  66% 92/140 [00:27<00:14,  3.37it/s]\u001b[A\n","Iteration:  66% 93/140 [00:27<00:13,  3.39it/s]\u001b[A\n","Iteration:  67% 94/140 [00:27<00:13,  3.37it/s]\u001b[A\n","Iteration:  68% 95/140 [00:28<00:13,  3.37it/s]\u001b[A\n","Iteration:  69% 96/140 [00:28<00:13,  3.37it/s]\u001b[A\n","Iteration:  69% 97/140 [00:28<00:12,  3.35it/s]\u001b[A\n","Iteration:  70% 98/140 [00:29<00:12,  3.35it/s]\u001b[A\n","Iteration:  71% 99/140 [00:29<00:12,  3.35it/s]\u001b[A03/04/2022 01:36:21 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:36:21 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:36:21 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  6.09it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.74it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.75it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.68it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.65it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.65it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.69it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.83it/s]\n","03/04/2022 01:36:22 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:36:22 - INFO - trainer -     intent_acc = 0.978\n","03/04/2022 01:36:22 - INFO - trainer -     loss = 0.21827543806284666\n","03/04/2022 01:36:22 - INFO - trainer -     sementic_frame_acc = 0.902\n","03/04/2022 01:36:22 - INFO - trainer -     slot_f1 = 0.969626168224299\n","03/04/2022 01:36:22 - INFO - trainer -     slot_precision = 0.9684947491248541\n","03/04/2022 01:36:22 - INFO - trainer -     slot_recall = 0.9707602339181286\n","03/04/2022 01:36:22 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:36:26 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:36:26 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  71% 100/140 [00:35<01:16,  1.92s/it]\u001b[A\n","Iteration:  72% 101/140 [00:35<00:56,  1.46s/it]\u001b[A\n","Iteration:  73% 102/140 [00:35<00:42,  1.11s/it]\u001b[A\n","Iteration:  74% 103/140 [00:36<00:31,  1.16it/s]\u001b[A\n","Iteration:  74% 104/140 [00:36<00:24,  1.45it/s]\u001b[A\n","Iteration:  75% 105/140 [00:36<00:19,  1.75it/s]\u001b[A\n","Iteration:  76% 106/140 [00:36<00:16,  2.04it/s]\u001b[A\n","Iteration:  76% 107/140 [00:37<00:14,  2.32it/s]\u001b[A\n","Iteration:  77% 108/140 [00:37<00:12,  2.55it/s]\u001b[A\n","Iteration:  78% 109/140 [00:37<00:11,  2.75it/s]\u001b[A\n","Iteration:  79% 110/140 [00:38<00:10,  2.91it/s]\u001b[A\n","Iteration:  79% 111/140 [00:38<00:09,  3.01it/s]\u001b[A\n","Iteration:  80% 112/140 [00:38<00:09,  3.11it/s]\u001b[A\n","Iteration:  81% 113/140 [00:39<00:08,  3.18it/s]\u001b[A\n","Iteration:  81% 114/140 [00:39<00:08,  3.25it/s]\u001b[A\n","Iteration:  82% 115/140 [00:39<00:07,  3.29it/s]\u001b[A\n","Iteration:  83% 116/140 [00:39<00:07,  3.31it/s]\u001b[A\n","Iteration:  84% 117/140 [00:40<00:06,  3.33it/s]\u001b[A\n","Iteration:  84% 118/140 [00:40<00:06,  3.36it/s]\u001b[A\n","Iteration:  85% 119/140 [00:40<00:06,  3.36it/s]\u001b[A\n","Iteration:  86% 120/140 [00:41<00:05,  3.37it/s]\u001b[A\n","Iteration:  86% 121/140 [00:41<00:05,  3.37it/s]\u001b[A\n","Iteration:  87% 122/140 [00:41<00:05,  3.36it/s]\u001b[A\n","Iteration:  88% 123/140 [00:42<00:05,  3.36it/s]\u001b[A\n","Iteration:  89% 124/140 [00:42<00:04,  3.36it/s]\u001b[A\n","Iteration:  89% 125/140 [00:42<00:04,  3.35it/s]\u001b[A\n","Iteration:  90% 126/140 [00:42<00:04,  3.36it/s]\u001b[A\n","Iteration:  91% 127/140 [00:43<00:03,  3.34it/s]\u001b[A\n","Iteration:  91% 128/140 [00:43<00:03,  3.34it/s]\u001b[A\n","Iteration:  92% 129/140 [00:43<00:03,  3.34it/s]\u001b[A\n","Iteration:  93% 130/140 [00:44<00:02,  3.33it/s]\u001b[A\n","Iteration:  94% 131/140 [00:44<00:02,  3.33it/s]\u001b[A\n","Iteration:  94% 132/140 [00:44<00:02,  3.33it/s]\u001b[A\n","Iteration:  95% 133/140 [00:45<00:02,  3.32it/s]\u001b[A\n","Iteration:  96% 134/140 [00:45<00:01,  3.33it/s]\u001b[A\n","Iteration:  96% 135/140 [00:45<00:01,  3.33it/s]\u001b[A\n","Iteration:  97% 136/140 [00:45<00:01,  3.32it/s]\u001b[A\n","Iteration:  98% 137/140 [00:46<00:00,  3.31it/s]\u001b[A\n","Iteration:  99% 138/140 [00:46<00:00,  3.33it/s]\u001b[A\n","Iteration:  99% 139/140 [00:46<00:00,  3.33it/s]\u001b[A\n","Iteration: 100% 140/140 [00:47<00:00,  2.97it/s]\n","Epoch:  60% 6/10 [04:37<03:06, 46.65s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:42,  3.31it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:41,  3.31it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:41,  3.28it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:41,  3.29it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:40,  3.31it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:40,  3.32it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:40,  3.32it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:39,  3.32it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:39,  3.34it/s]\u001b[A\n","Iteration:   7% 10/140 [00:03<00:38,  3.35it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.33it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:38,  3.35it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:37,  3.34it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.34it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.32it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:37,  3.29it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:37,  3.31it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.31it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:36,  3.30it/s]\u001b[A\n","Iteration:  14% 20/140 [00:06<00:36,  3.30it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.31it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:35,  3.32it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:35,  3.31it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:34,  3.33it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:34,  3.33it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:34,  3.35it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.34it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:33,  3.35it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:33,  3.33it/s]\u001b[A\n","Iteration:  21% 30/140 [00:09<00:33,  3.33it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.31it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:32,  3.33it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:32,  3.33it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:31,  3.33it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.33it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:31,  3.31it/s]\u001b[A\n","Iteration:  26% 37/140 [00:11<00:31,  3.32it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.31it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.29it/s]\u001b[A\n","Iteration:  29% 40/140 [00:12<00:30,  3.30it/s]\u001b[A\n","Iteration:  29% 41/140 [00:12<00:29,  3.30it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:29,  3.32it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:29,  3.33it/s]\u001b[A\n","Iteration:  31% 44/140 [00:13<00:28,  3.33it/s]\u001b[A\n","Iteration:  32% 45/140 [00:13<00:28,  3.33it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:28,  3.34it/s]\u001b[A\n","Iteration:  34% 47/140 [00:14<00:28,  3.32it/s]\u001b[A\n","Iteration:  34% 48/140 [00:14<00:27,  3.33it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:27,  3.32it/s]\u001b[A\n","Iteration:  36% 50/140 [00:15<00:27,  3.31it/s]\u001b[A\n","Iteration:  36% 51/140 [00:15<00:27,  3.27it/s]\u001b[A\n","Iteration:  37% 52/140 [00:15<00:26,  3.31it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:26,  3.31it/s]\u001b[A\n","Iteration:  39% 54/140 [00:16<00:25,  3.33it/s]\u001b[A\n","Iteration:  39% 55/140 [00:16<00:25,  3.33it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:25,  3.32it/s]\u001b[A\n","Iteration:  41% 57/140 [00:17<00:24,  3.32it/s]\u001b[A\n","Iteration:  41% 58/140 [00:17<00:24,  3.30it/s]\u001b[A\n","Iteration:  42% 59/140 [00:17<00:24,  3.31it/s]\u001b[A\n","Iteration:  43% 60/140 [00:18<00:24,  3.31it/s]\u001b[A\n","Iteration:  44% 61/140 [00:18<00:23,  3.32it/s]\u001b[A\n","Iteration:  44% 62/140 [00:18<00:23,  3.33it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:23,  3.33it/s]\u001b[A\n","Iteration:  46% 64/140 [00:19<00:22,  3.32it/s]\u001b[A\n","Iteration:  46% 65/140 [00:19<00:22,  3.31it/s]\u001b[A\n","Iteration:  47% 66/140 [00:19<00:22,  3.31it/s]\u001b[A\n","Iteration:  48% 67/140 [00:20<00:21,  3.33it/s]\u001b[A\n","Iteration:  49% 68/140 [00:20<00:21,  3.29it/s]\u001b[A\n","Iteration:  49% 69/140 [00:20<00:21,  3.31it/s]\u001b[A\n","Iteration:  50% 70/140 [00:21<00:21,  3.32it/s]\u001b[A\n","Iteration:  51% 71/140 [00:21<00:20,  3.33it/s]\u001b[A\n","Iteration:  51% 72/140 [00:21<00:20,  3.34it/s]\u001b[A\n","Iteration:  52% 73/140 [00:21<00:20,  3.33it/s]\u001b[A\n","Iteration:  53% 74/140 [00:22<00:19,  3.34it/s]\u001b[A\n","Iteration:  54% 75/140 [00:22<00:19,  3.33it/s]\u001b[A\n","Iteration:  54% 76/140 [00:22<00:19,  3.33it/s]\u001b[A\n","Iteration:  55% 77/140 [00:23<00:18,  3.32it/s]\u001b[A\n","Iteration:  56% 78/140 [00:23<00:18,  3.31it/s]\u001b[A\n","Iteration:  56% 79/140 [00:23<00:18,  3.30it/s]\u001b[A\n","Iteration:  57% 80/140 [00:24<00:18,  3.31it/s]\u001b[A\n","Iteration:  58% 81/140 [00:24<00:17,  3.33it/s]\u001b[A\n","Iteration:  59% 82/140 [00:24<00:17,  3.33it/s]\u001b[A\n","Iteration:  59% 83/140 [00:24<00:17,  3.33it/s]\u001b[A\n","Iteration:  60% 84/140 [00:25<00:16,  3.33it/s]\u001b[A\n","Iteration:  61% 85/140 [00:25<00:16,  3.32it/s]\u001b[A\n","Iteration:  61% 86/140 [00:25<00:16,  3.34it/s]\u001b[A\n","Iteration:  62% 87/140 [00:26<00:15,  3.35it/s]\u001b[A\n","Iteration:  63% 88/140 [00:26<00:15,  3.36it/s]\u001b[A\n","Iteration:  64% 89/140 [00:26<00:15,  3.36it/s]\u001b[A\n","Iteration:  64% 90/140 [00:27<00:14,  3.35it/s]\u001b[A\n","Iteration:  65% 91/140 [00:27<00:14,  3.34it/s]\u001b[A\n","Iteration:  66% 92/140 [00:27<00:14,  3.34it/s]\u001b[A\n","Iteration:  66% 93/140 [00:27<00:13,  3.37it/s]\u001b[A\n","Iteration:  67% 94/140 [00:28<00:13,  3.35it/s]\u001b[A\n","Iteration:  68% 95/140 [00:28<00:13,  3.35it/s]\u001b[A\n","Iteration:  69% 96/140 [00:28<00:13,  3.36it/s]\u001b[A\n","Iteration:  69% 97/140 [00:29<00:12,  3.35it/s]\u001b[A\n","Iteration:  70% 98/140 [00:29<00:12,  3.35it/s]\u001b[A\n","Iteration:  71% 99/140 [00:29<00:12,  3.34it/s]\u001b[A\n","Iteration:  71% 100/140 [00:30<00:11,  3.35it/s]\u001b[A\n","Iteration:  72% 101/140 [00:30<00:11,  3.36it/s]\u001b[A\n","Iteration:  73% 102/140 [00:30<00:11,  3.35it/s]\u001b[A\n","Iteration:  74% 103/140 [00:30<00:11,  3.36it/s]\u001b[A\n","Iteration:  74% 104/140 [00:31<00:10,  3.37it/s]\u001b[A\n","Iteration:  75% 105/140 [00:31<00:10,  3.36it/s]\u001b[A\n","Iteration:  76% 106/140 [00:31<00:10,  3.37it/s]\u001b[A\n","Iteration:  76% 107/140 [00:32<00:09,  3.38it/s]\u001b[A\n","Iteration:  77% 108/140 [00:32<00:09,  3.38it/s]\u001b[A\n","Iteration:  78% 109/140 [00:32<00:09,  3.38it/s]\u001b[A\n","Iteration:  79% 110/140 [00:33<00:08,  3.38it/s]\u001b[A\n","Iteration:  79% 111/140 [00:33<00:08,  3.39it/s]\u001b[A\n","Iteration:  80% 112/140 [00:33<00:08,  3.38it/s]\u001b[A\n","Iteration:  81% 113/140 [00:33<00:07,  3.38it/s]\u001b[A\n","Iteration:  81% 114/140 [00:34<00:07,  3.38it/s]\u001b[A\n","Iteration:  82% 115/140 [00:34<00:07,  3.38it/s]\u001b[A\n","Iteration:  83% 116/140 [00:34<00:07,  3.38it/s]\u001b[A\n","Iteration:  84% 117/140 [00:35<00:06,  3.36it/s]\u001b[A\n","Iteration:  84% 118/140 [00:35<00:06,  3.38it/s]\u001b[A\n","Iteration:  85% 119/140 [00:35<00:06,  3.36it/s]\u001b[A\n","Iteration:  86% 120/140 [00:35<00:05,  3.37it/s]\u001b[A\n","Iteration:  86% 121/140 [00:36<00:05,  3.37it/s]\u001b[A\n","Iteration:  87% 122/140 [00:36<00:05,  3.36it/s]\u001b[A\n","Iteration:  88% 123/140 [00:36<00:05,  3.35it/s]\u001b[A\n","Iteration:  89% 124/140 [00:37<00:04,  3.37it/s]\u001b[A\n","Iteration:  89% 125/140 [00:37<00:04,  3.36it/s]\u001b[A\n","Iteration:  90% 126/140 [00:37<00:04,  3.38it/s]\u001b[A\n","Iteration:  91% 127/140 [00:38<00:03,  3.37it/s]\u001b[A\n","Iteration:  91% 128/140 [00:38<00:03,  3.39it/s]\u001b[A\n","Iteration:  92% 129/140 [00:38<00:03,  3.38it/s]\u001b[A\n","Iteration:  93% 130/140 [00:38<00:02,  3.38it/s]\u001b[A\n","Iteration:  94% 131/140 [00:39<00:02,  3.37it/s]\u001b[A\n","Iteration:  94% 132/140 [00:39<00:02,  3.38it/s]\u001b[A\n","Iteration:  95% 133/140 [00:39<00:02,  3.37it/s]\u001b[A\n","Iteration:  96% 134/140 [00:40<00:01,  3.37it/s]\u001b[A\n","Iteration:  96% 135/140 [00:40<00:01,  3.37it/s]\u001b[A\n","Iteration:  97% 136/140 [00:40<00:01,  3.37it/s]\u001b[A\n","Iteration:  98% 137/140 [00:41<00:00,  3.39it/s]\u001b[A\n","Iteration:  99% 138/140 [00:41<00:00,  3.38it/s]\u001b[A\n","Iteration:  99% 139/140 [00:41<00:00,  3.38it/s]\u001b[A\n","Iteration: 100% 140/140 [00:41<00:00,  3.34it/s]\n","Epoch:  70% 7/10 [05:19<02:15, 45.10s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:41,  3.34it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:41,  3.35it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:40,  3.38it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:40,  3.37it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:40,  3.37it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:39,  3.38it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:39,  3.38it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:38,  3.39it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:38,  3.39it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:38,  3.39it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.38it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:37,  3.37it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:37,  3.36it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.37it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:36,  3.38it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:36,  3.36it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:36,  3.38it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.39it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:35,  3.37it/s]\u001b[A03/04/2022 01:37:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:37:26 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:37:26 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  6.02it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.82it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.78it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.68it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.70it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.70it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.72it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.86it/s]\n","03/04/2022 01:37:27 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:37:27 - INFO - trainer -     intent_acc = 0.982\n","03/04/2022 01:37:27 - INFO - trainer -     loss = 0.19726763805374503\n","03/04/2022 01:37:27 - INFO - trainer -     sementic_frame_acc = 0.906\n","03/04/2022 01:37:27 - INFO - trainer -     slot_f1 = 0.9710780017528484\n","03/04/2022 01:37:27 - INFO - trainer -     slot_precision = 0.9702276707530648\n","03/04/2022 01:37:27 - INFO - trainer -     slot_recall = 0.9719298245614035\n","03/04/2022 01:37:27 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:37:31 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:37:31 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  14% 20/140 [00:11<03:42,  1.85s/it]\u001b[A\n","Iteration:  15% 21/140 [00:11<02:46,  1.40s/it]\u001b[A\n","Iteration:  16% 22/140 [00:11<02:05,  1.07s/it]\u001b[A\n","Iteration:  16% 23/140 [00:12<01:37,  1.20it/s]\u001b[A\n","Iteration:  17% 24/140 [00:12<01:17,  1.49it/s]\u001b[A\n","Iteration:  18% 25/140 [00:12<01:04,  1.79it/s]\u001b[A\n","Iteration:  19% 26/140 [00:12<00:54,  2.09it/s]\u001b[A\n","Iteration:  19% 27/140 [00:13<00:47,  2.37it/s]\u001b[A\n","Iteration:  20% 28/140 [00:13<00:42,  2.61it/s]\u001b[A\n","Iteration:  21% 29/140 [00:13<00:39,  2.82it/s]\u001b[A\n","Iteration:  21% 30/140 [00:14<00:36,  2.98it/s]\u001b[A\n","Iteration:  22% 31/140 [00:14<00:35,  3.11it/s]\u001b[A\n","Iteration:  23% 32/140 [00:14<00:33,  3.19it/s]\u001b[A\n","Iteration:  24% 33/140 [00:14<00:32,  3.26it/s]\u001b[A\n","Iteration:  24% 34/140 [00:15<00:31,  3.32it/s]\u001b[A\n","Iteration:  25% 35/140 [00:15<00:31,  3.32it/s]\u001b[A\n","Iteration:  26% 36/140 [00:15<00:31,  3.33it/s]\u001b[A\n","Iteration:  26% 37/140 [00:16<00:30,  3.35it/s]\u001b[A\n","Iteration:  27% 38/140 [00:16<00:30,  3.37it/s]\u001b[A\n","Iteration:  28% 39/140 [00:16<00:29,  3.37it/s]\u001b[A\n","Iteration:  29% 40/140 [00:17<00:29,  3.40it/s]\u001b[A\n","Iteration:  29% 41/140 [00:17<00:28,  3.42it/s]\u001b[A\n","Iteration:  30% 42/140 [00:17<00:29,  3.37it/s]\u001b[A\n","Iteration:  31% 43/140 [00:17<00:28,  3.36it/s]\u001b[A\n","Iteration:  31% 44/140 [00:18<00:28,  3.35it/s]\u001b[A\n","Iteration:  32% 45/140 [00:18<00:28,  3.33it/s]\u001b[A\n","Iteration:  33% 46/140 [00:18<00:28,  3.34it/s]\u001b[A\n","Iteration:  34% 47/140 [00:19<00:27,  3.36it/s]\u001b[A\n","Iteration:  34% 48/140 [00:19<00:27,  3.37it/s]\u001b[A\n","Iteration:  35% 49/140 [00:19<00:26,  3.39it/s]\u001b[A\n","Iteration:  36% 50/140 [00:19<00:26,  3.38it/s]\u001b[A\n","Iteration:  36% 51/140 [00:20<00:26,  3.33it/s]\u001b[A\n","Iteration:  37% 52/140 [00:20<00:26,  3.34it/s]\u001b[A\n","Iteration:  38% 53/140 [00:20<00:26,  3.33it/s]\u001b[A\n","Iteration:  39% 54/140 [00:21<00:25,  3.35it/s]\u001b[A\n","Iteration:  39% 55/140 [00:21<00:25,  3.38it/s]\u001b[A\n","Iteration:  40% 56/140 [00:21<00:25,  3.35it/s]\u001b[A\n","Iteration:  41% 57/140 [00:22<00:24,  3.36it/s]\u001b[A\n","Iteration:  41% 58/140 [00:22<00:24,  3.36it/s]\u001b[A\n","Iteration:  42% 59/140 [00:22<00:24,  3.37it/s]\u001b[A\n","Iteration:  43% 60/140 [00:22<00:23,  3.37it/s]\u001b[A\n","Iteration:  44% 61/140 [00:23<00:23,  3.36it/s]\u001b[A\n","Iteration:  44% 62/140 [00:23<00:23,  3.32it/s]\u001b[A\n","Iteration:  45% 63/140 [00:23<00:23,  3.31it/s]\u001b[A\n","Iteration:  46% 64/140 [00:24<00:22,  3.31it/s]\u001b[A\n","Iteration:  46% 65/140 [00:24<00:22,  3.31it/s]\u001b[A\n","Iteration:  47% 66/140 [00:24<00:22,  3.33it/s]\u001b[A\n","Iteration:  48% 67/140 [00:25<00:21,  3.35it/s]\u001b[A\n","Iteration:  49% 68/140 [00:25<00:21,  3.35it/s]\u001b[A\n","Iteration:  49% 69/140 [00:25<00:21,  3.35it/s]\u001b[A\n","Iteration:  50% 70/140 [00:25<00:20,  3.35it/s]\u001b[A\n","Iteration:  51% 71/140 [00:26<00:20,  3.33it/s]\u001b[A\n","Iteration:  51% 72/140 [00:26<00:20,  3.33it/s]\u001b[A\n","Iteration:  52% 73/140 [00:26<00:20,  3.31it/s]\u001b[A\n","Iteration:  53% 74/140 [00:27<00:19,  3.32it/s]\u001b[A\n","Iteration:  54% 75/140 [00:27<00:19,  3.31it/s]\u001b[A\n","Iteration:  54% 76/140 [00:27<00:19,  3.30it/s]\u001b[A\n","Iteration:  55% 77/140 [00:28<00:19,  3.30it/s]\u001b[A\n","Iteration:  56% 78/140 [00:28<00:18,  3.31it/s]\u001b[A\n","Iteration:  56% 79/140 [00:28<00:18,  3.32it/s]\u001b[A\n","Iteration:  57% 80/140 [00:28<00:18,  3.32it/s]\u001b[A\n","Iteration:  58% 81/140 [00:29<00:17,  3.32it/s]\u001b[A\n","Iteration:  59% 82/140 [00:29<00:17,  3.31it/s]\u001b[A\n","Iteration:  59% 83/140 [00:29<00:17,  3.28it/s]\u001b[A\n","Iteration:  60% 84/140 [00:30<00:17,  3.28it/s]\u001b[A\n","Iteration:  61% 85/140 [00:30<00:16,  3.26it/s]\u001b[A\n","Iteration:  61% 86/140 [00:30<00:16,  3.30it/s]\u001b[A\n","Iteration:  62% 87/140 [00:31<00:15,  3.32it/s]\u001b[A\n","Iteration:  63% 88/140 [00:31<00:15,  3.32it/s]\u001b[A\n","Iteration:  64% 89/140 [00:31<00:15,  3.35it/s]\u001b[A\n","Iteration:  64% 90/140 [00:32<00:14,  3.34it/s]\u001b[A\n","Iteration:  65% 91/140 [00:32<00:14,  3.35it/s]\u001b[A\n","Iteration:  66% 92/140 [00:32<00:14,  3.34it/s]\u001b[A\n","Iteration:  66% 93/140 [00:32<00:14,  3.35it/s]\u001b[A\n","Iteration:  67% 94/140 [00:33<00:13,  3.36it/s]\u001b[A\n","Iteration:  68% 95/140 [00:33<00:13,  3.36it/s]\u001b[A\n","Iteration:  69% 96/140 [00:33<00:13,  3.34it/s]\u001b[A\n","Iteration:  69% 97/140 [00:34<00:12,  3.32it/s]\u001b[A\n","Iteration:  70% 98/140 [00:34<00:12,  3.33it/s]\u001b[A\n","Iteration:  71% 99/140 [00:34<00:12,  3.35it/s]\u001b[A\n","Iteration:  71% 100/140 [00:34<00:11,  3.36it/s]\u001b[A\n","Iteration:  72% 101/140 [00:35<00:11,  3.36it/s]\u001b[A\n","Iteration:  73% 102/140 [00:35<00:11,  3.36it/s]\u001b[A\n","Iteration:  74% 103/140 [00:35<00:10,  3.36it/s]\u001b[A\n","Iteration:  74% 104/140 [00:36<00:10,  3.35it/s]\u001b[A\n","Iteration:  75% 105/140 [00:36<00:10,  3.35it/s]\u001b[A\n","Iteration:  76% 106/140 [00:36<00:10,  3.34it/s]\u001b[A\n","Iteration:  76% 107/140 [00:37<00:09,  3.35it/s]\u001b[A\n","Iteration:  77% 108/140 [00:37<00:09,  3.34it/s]\u001b[A\n","Iteration:  78% 109/140 [00:37<00:09,  3.37it/s]\u001b[A\n","Iteration:  79% 110/140 [00:37<00:08,  3.35it/s]\u001b[A\n","Iteration:  79% 111/140 [00:38<00:08,  3.35it/s]\u001b[A\n","Iteration:  80% 112/140 [00:38<00:08,  3.34it/s]\u001b[A\n","Iteration:  81% 113/140 [00:38<00:08,  3.35it/s]\u001b[A\n","Iteration:  81% 114/140 [00:39<00:07,  3.37it/s]\u001b[A\n","Iteration:  82% 115/140 [00:39<00:07,  3.37it/s]\u001b[A\n","Iteration:  83% 116/140 [00:39<00:07,  3.38it/s]\u001b[A\n","Iteration:  84% 117/140 [00:40<00:06,  3.35it/s]\u001b[A\n","Iteration:  84% 118/140 [00:40<00:06,  3.35it/s]\u001b[A\n","Iteration:  85% 119/140 [00:40<00:06,  3.35it/s]\u001b[A\n","Iteration:  86% 120/140 [00:40<00:05,  3.36it/s]\u001b[A\n","Iteration:  86% 121/140 [00:41<00:05,  3.36it/s]\u001b[A\n","Iteration:  87% 122/140 [00:41<00:05,  3.36it/s]\u001b[A\n","Iteration:  88% 123/140 [00:41<00:05,  3.33it/s]\u001b[A\n","Iteration:  89% 124/140 [00:42<00:04,  3.34it/s]\u001b[A\n","Iteration:  89% 125/140 [00:42<00:04,  3.35it/s]\u001b[A\n","Iteration:  90% 126/140 [00:42<00:04,  3.35it/s]\u001b[A\n","Iteration:  91% 127/140 [00:43<00:03,  3.35it/s]\u001b[A\n","Iteration:  91% 128/140 [00:43<00:03,  3.36it/s]\u001b[A\n","Iteration:  92% 129/140 [00:43<00:03,  3.33it/s]\u001b[A\n","Iteration:  93% 130/140 [00:43<00:03,  3.32it/s]\u001b[A\n","Iteration:  94% 131/140 [00:44<00:02,  3.33it/s]\u001b[A\n","Iteration:  94% 132/140 [00:44<00:02,  3.33it/s]\u001b[A\n","Iteration:  95% 133/140 [00:44<00:02,  3.35it/s]\u001b[A\n","Iteration:  96% 134/140 [00:45<00:01,  3.36it/s]\u001b[A\n","Iteration:  96% 135/140 [00:45<00:01,  3.34it/s]\u001b[A\n","Iteration:  97% 136/140 [00:45<00:01,  3.34it/s]\u001b[A\n","Iteration:  98% 137/140 [00:46<00:00,  3.34it/s]\u001b[A\n","Iteration:  99% 138/140 [00:46<00:00,  3.34it/s]\u001b[A\n","Iteration:  99% 139/140 [00:46<00:00,  3.34it/s]\u001b[A\n","Iteration: 100% 140/140 [00:46<00:00,  2.98it/s]\n","Epoch:  80% 8/10 [06:06<01:31, 45.68s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:41,  3.37it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:40,  3.38it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:40,  3.35it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:40,  3.36it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:40,  3.37it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:39,  3.37it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:39,  3.37it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:39,  3.38it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:38,  3.36it/s]\u001b[A\n","Iteration:   7% 10/140 [00:02<00:38,  3.37it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.38it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:37,  3.39it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:37,  3.39it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.37it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.36it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:37,  3.35it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:36,  3.35it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.36it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:36,  3.36it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:35,  3.36it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.36it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:34,  3.37it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:34,  3.39it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:34,  3.39it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:33,  3.40it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:33,  3.39it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.40it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:32,  3.40it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:32,  3.40it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:32,  3.40it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.40it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:31,  3.39it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:31,  3.39it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:31,  3.38it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.38it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:30,  3.38it/s]\u001b[A\n","Iteration:  26% 37/140 [00:10<00:30,  3.36it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.35it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.34it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:29,  3.37it/s]\u001b[A\n","Iteration:  29% 41/140 [00:12<00:29,  3.38it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:28,  3.39it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:28,  3.40it/s]\u001b[A\n","Iteration:  31% 44/140 [00:13<00:28,  3.39it/s]\u001b[A\n","Iteration:  32% 45/140 [00:13<00:27,  3.40it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:27,  3.40it/s]\u001b[A\n","Iteration:  34% 47/140 [00:13<00:27,  3.41it/s]\u001b[A\n","Iteration:  34% 48/140 [00:14<00:27,  3.40it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:26,  3.40it/s]\u001b[A\n","Iteration:  36% 50/140 [00:14<00:26,  3.40it/s]\u001b[A\n","Iteration:  36% 51/140 [00:15<00:26,  3.40it/s]\u001b[A\n","Iteration:  37% 52/140 [00:15<00:26,  3.38it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:25,  3.38it/s]\u001b[A\n","Iteration:  39% 54/140 [00:15<00:25,  3.36it/s]\u001b[A\n","Iteration:  39% 55/140 [00:16<00:25,  3.38it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:24,  3.38it/s]\u001b[A\n","Iteration:  41% 57/140 [00:16<00:24,  3.39it/s]\u001b[A\n","Iteration:  41% 58/140 [00:17<00:24,  3.40it/s]\u001b[A\n","Iteration:  42% 59/140 [00:17<00:23,  3.40it/s]\u001b[A\n","Iteration:  43% 60/140 [00:17<00:23,  3.39it/s]\u001b[A\n","Iteration:  44% 61/140 [00:18<00:23,  3.40it/s]\u001b[A\n","Iteration:  44% 62/140 [00:18<00:22,  3.40it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:22,  3.41it/s]\u001b[A\n","Iteration:  46% 64/140 [00:18<00:22,  3.40it/s]\u001b[A\n","Iteration:  46% 65/140 [00:19<00:22,  3.39it/s]\u001b[A\n","Iteration:  47% 66/140 [00:19<00:21,  3.40it/s]\u001b[A\n","Iteration:  48% 67/140 [00:19<00:21,  3.39it/s]\u001b[A\n","Iteration:  49% 68/140 [00:20<00:21,  3.39it/s]\u001b[A\n","Iteration:  49% 69/140 [00:20<00:20,  3.39it/s]\u001b[A\n","Iteration:  50% 70/140 [00:20<00:20,  3.38it/s]\u001b[A\n","Iteration:  51% 71/140 [00:20<00:20,  3.38it/s]\u001b[A\n","Iteration:  51% 72/140 [00:21<00:20,  3.38it/s]\u001b[A\n","Iteration:  52% 73/140 [00:21<00:19,  3.39it/s]\u001b[A\n","Iteration:  53% 74/140 [00:21<00:19,  3.40it/s]\u001b[A\n","Iteration:  54% 75/140 [00:22<00:19,  3.40it/s]\u001b[A\n","Iteration:  54% 76/140 [00:22<00:18,  3.39it/s]\u001b[A\n","Iteration:  55% 77/140 [00:22<00:18,  3.37it/s]\u001b[A\n","Iteration:  56% 78/140 [00:23<00:18,  3.36it/s]\u001b[A\n","Iteration:  56% 79/140 [00:23<00:18,  3.36it/s]\u001b[A03/04/2022 01:38:31 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:38:31 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:38:31 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  5.96it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.75it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.78it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.68it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.67it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.70it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.69it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.84it/s]\n","03/04/2022 01:38:32 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:38:32 - INFO - trainer -     intent_acc = 0.978\n","03/04/2022 01:38:32 - INFO - trainer -     loss = 0.21026142733171582\n","03/04/2022 01:38:32 - INFO - trainer -     sementic_frame_acc = 0.906\n","03/04/2022 01:38:32 - INFO - trainer -     slot_f1 = 0.9725306838106371\n","03/04/2022 01:38:32 - INFO - trainer -     slot_precision = 0.9719626168224299\n","03/04/2022 01:38:32 - INFO - trainer -     slot_recall = 0.9730994152046784\n","03/04/2022 01:38:32 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:38:36 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:38:36 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration:  57% 80/140 [00:28<01:53,  1.90s/it]\u001b[A\n","Iteration:  58% 81/140 [00:29<01:24,  1.44s/it]\u001b[A\n","Iteration:  59% 82/140 [00:29<01:03,  1.09s/it]\u001b[A\n","Iteration:  59% 83/140 [00:29<00:48,  1.17it/s]\u001b[A\n","Iteration:  60% 84/140 [00:30<00:38,  1.46it/s]\u001b[A\n","Iteration:  61% 85/140 [00:30<00:31,  1.76it/s]\u001b[A\n","Iteration:  61% 86/140 [00:30<00:26,  2.06it/s]\u001b[A\n","Iteration:  62% 87/140 [00:31<00:22,  2.33it/s]\u001b[A\n","Iteration:  63% 88/140 [00:31<00:20,  2.58it/s]\u001b[A\n","Iteration:  64% 89/140 [00:31<00:18,  2.79it/s]\u001b[A\n","Iteration:  64% 90/140 [00:32<00:16,  2.95it/s]\u001b[A\n","Iteration:  65% 91/140 [00:32<00:15,  3.07it/s]\u001b[A\n","Iteration:  66% 92/140 [00:32<00:15,  3.16it/s]\u001b[A\n","Iteration:  66% 93/140 [00:32<00:14,  3.23it/s]\u001b[A\n","Iteration:  67% 94/140 [00:33<00:14,  3.27it/s]\u001b[A\n","Iteration:  68% 95/140 [00:33<00:13,  3.32it/s]\u001b[A\n","Iteration:  69% 96/140 [00:33<00:13,  3.34it/s]\u001b[A\n","Iteration:  69% 97/140 [00:34<00:12,  3.36it/s]\u001b[A\n","Iteration:  70% 98/140 [00:34<00:12,  3.37it/s]\u001b[A\n","Iteration:  71% 99/140 [00:34<00:12,  3.38it/s]\u001b[A\n","Iteration:  71% 100/140 [00:34<00:11,  3.39it/s]\u001b[A\n","Iteration:  72% 101/140 [00:35<00:11,  3.38it/s]\u001b[A\n","Iteration:  73% 102/140 [00:35<00:11,  3.29it/s]\u001b[A\n","Iteration:  74% 103/140 [00:35<00:11,  3.32it/s]\u001b[A\n","Iteration:  74% 104/140 [00:36<00:10,  3.31it/s]\u001b[A\n","Iteration:  75% 105/140 [00:36<00:10,  3.31it/s]\u001b[A\n","Iteration:  76% 106/140 [00:36<00:10,  3.30it/s]\u001b[A\n","Iteration:  76% 107/140 [00:37<00:09,  3.30it/s]\u001b[A\n","Iteration:  77% 108/140 [00:37<00:09,  3.33it/s]\u001b[A\n","Iteration:  78% 109/140 [00:37<00:09,  3.33it/s]\u001b[A\n","Iteration:  79% 110/140 [00:37<00:08,  3.34it/s]\u001b[A\n","Iteration:  79% 111/140 [00:38<00:08,  3.38it/s]\u001b[A\n","Iteration:  80% 112/140 [00:38<00:08,  3.38it/s]\u001b[A\n","Iteration:  81% 113/140 [00:38<00:07,  3.38it/s]\u001b[A\n","Iteration:  81% 114/140 [00:39<00:07,  3.36it/s]\u001b[A\n","Iteration:  82% 115/140 [00:39<00:07,  3.35it/s]\u001b[A\n","Iteration:  83% 116/140 [00:39<00:07,  3.37it/s]\u001b[A\n","Iteration:  84% 117/140 [00:40<00:06,  3.37it/s]\u001b[A\n","Iteration:  84% 118/140 [00:40<00:06,  3.38it/s]\u001b[A\n","Iteration:  85% 119/140 [00:40<00:06,  3.37it/s]\u001b[A\n","Iteration:  86% 120/140 [00:40<00:05,  3.35it/s]\u001b[A\n","Iteration:  86% 121/140 [00:41<00:05,  3.37it/s]\u001b[A\n","Iteration:  87% 122/140 [00:41<00:05,  3.36it/s]\u001b[A\n","Iteration:  88% 123/140 [00:41<00:05,  3.36it/s]\u001b[A\n","Iteration:  89% 124/140 [00:42<00:04,  3.38it/s]\u001b[A\n","Iteration:  89% 125/140 [00:42<00:04,  3.39it/s]\u001b[A\n","Iteration:  90% 126/140 [00:42<00:04,  3.35it/s]\u001b[A\n","Iteration:  91% 127/140 [00:43<00:03,  3.36it/s]\u001b[A\n","Iteration:  91% 128/140 [00:43<00:03,  3.37it/s]\u001b[A\n","Iteration:  92% 129/140 [00:43<00:03,  3.37it/s]\u001b[A\n","Iteration:  93% 130/140 [00:43<00:02,  3.35it/s]\u001b[A\n","Iteration:  94% 131/140 [00:44<00:02,  3.36it/s]\u001b[A\n","Iteration:  94% 132/140 [00:44<00:02,  3.35it/s]\u001b[A\n","Iteration:  95% 133/140 [00:44<00:02,  3.34it/s]\u001b[A\n","Iteration:  96% 134/140 [00:45<00:01,  3.36it/s]\u001b[A\n","Iteration:  96% 135/140 [00:45<00:01,  3.36it/s]\u001b[A\n","Iteration:  97% 136/140 [00:45<00:01,  3.36it/s]\u001b[A\n","Iteration:  98% 137/140 [00:45<00:00,  3.36it/s]\u001b[A\n","Iteration:  99% 138/140 [00:46<00:00,  3.37it/s]\u001b[A\n","Iteration:  99% 139/140 [00:46<00:00,  3.37it/s]\u001b[A\n","Iteration: 100% 140/140 [00:46<00:00,  2.99it/s]\n","Epoch:  90% 9/10 [06:53<00:46, 46.05s/it]\n","Iteration:   0% 0/140 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/140 [00:00<00:42,  3.25it/s]\u001b[A\n","Iteration:   1% 2/140 [00:00<00:41,  3.31it/s]\u001b[A\n","Iteration:   2% 3/140 [00:00<00:41,  3.31it/s]\u001b[A\n","Iteration:   3% 4/140 [00:01<00:40,  3.33it/s]\u001b[A\n","Iteration:   4% 5/140 [00:01<00:41,  3.29it/s]\u001b[A\n","Iteration:   4% 6/140 [00:01<00:40,  3.33it/s]\u001b[A\n","Iteration:   5% 7/140 [00:02<00:40,  3.32it/s]\u001b[A\n","Iteration:   6% 8/140 [00:02<00:39,  3.32it/s]\u001b[A\n","Iteration:   6% 9/140 [00:02<00:39,  3.32it/s]\u001b[A\n","Iteration:   7% 10/140 [00:03<00:39,  3.33it/s]\u001b[A\n","Iteration:   8% 11/140 [00:03<00:38,  3.32it/s]\u001b[A\n","Iteration:   9% 12/140 [00:03<00:38,  3.33it/s]\u001b[A\n","Iteration:   9% 13/140 [00:03<00:38,  3.34it/s]\u001b[A\n","Iteration:  10% 14/140 [00:04<00:37,  3.32it/s]\u001b[A\n","Iteration:  11% 15/140 [00:04<00:37,  3.33it/s]\u001b[A\n","Iteration:  11% 16/140 [00:04<00:37,  3.34it/s]\u001b[A\n","Iteration:  12% 17/140 [00:05<00:36,  3.34it/s]\u001b[A\n","Iteration:  13% 18/140 [00:05<00:36,  3.37it/s]\u001b[A\n","Iteration:  14% 19/140 [00:05<00:35,  3.37it/s]\u001b[A\n","Iteration:  14% 20/140 [00:05<00:35,  3.43it/s]\u001b[A\n","Iteration:  15% 21/140 [00:06<00:35,  3.38it/s]\u001b[A\n","Iteration:  16% 22/140 [00:06<00:34,  3.37it/s]\u001b[A\n","Iteration:  16% 23/140 [00:06<00:34,  3.36it/s]\u001b[A\n","Iteration:  17% 24/140 [00:07<00:34,  3.37it/s]\u001b[A\n","Iteration:  18% 25/140 [00:07<00:34,  3.37it/s]\u001b[A\n","Iteration:  19% 26/140 [00:07<00:33,  3.37it/s]\u001b[A\n","Iteration:  19% 27/140 [00:08<00:33,  3.38it/s]\u001b[A\n","Iteration:  20% 28/140 [00:08<00:33,  3.38it/s]\u001b[A\n","Iteration:  21% 29/140 [00:08<00:32,  3.36it/s]\u001b[A\n","Iteration:  21% 30/140 [00:08<00:32,  3.36it/s]\u001b[A\n","Iteration:  22% 31/140 [00:09<00:32,  3.36it/s]\u001b[A\n","Iteration:  23% 32/140 [00:09<00:32,  3.35it/s]\u001b[A\n","Iteration:  24% 33/140 [00:09<00:31,  3.36it/s]\u001b[A\n","Iteration:  24% 34/140 [00:10<00:31,  3.35it/s]\u001b[A\n","Iteration:  25% 35/140 [00:10<00:31,  3.34it/s]\u001b[A\n","Iteration:  26% 36/140 [00:10<00:31,  3.34it/s]\u001b[A\n","Iteration:  26% 37/140 [00:11<00:30,  3.35it/s]\u001b[A\n","Iteration:  27% 38/140 [00:11<00:30,  3.35it/s]\u001b[A\n","Iteration:  28% 39/140 [00:11<00:30,  3.35it/s]\u001b[A\n","Iteration:  29% 40/140 [00:11<00:29,  3.37it/s]\u001b[A\n","Iteration:  29% 41/140 [00:12<00:29,  3.36it/s]\u001b[A\n","Iteration:  30% 42/140 [00:12<00:29,  3.36it/s]\u001b[A\n","Iteration:  31% 43/140 [00:12<00:28,  3.36it/s]\u001b[A\n","Iteration:  31% 44/140 [00:13<00:28,  3.37it/s]\u001b[A\n","Iteration:  32% 45/140 [00:13<00:28,  3.37it/s]\u001b[A\n","Iteration:  33% 46/140 [00:13<00:27,  3.37it/s]\u001b[A\n","Iteration:  34% 47/140 [00:14<00:27,  3.37it/s]\u001b[A\n","Iteration:  34% 48/140 [00:14<00:27,  3.36it/s]\u001b[A\n","Iteration:  35% 49/140 [00:14<00:27,  3.37it/s]\u001b[A\n","Iteration:  36% 50/140 [00:14<00:26,  3.36it/s]\u001b[A\n","Iteration:  36% 51/140 [00:15<00:26,  3.35it/s]\u001b[A\n","Iteration:  37% 52/140 [00:15<00:26,  3.34it/s]\u001b[A\n","Iteration:  38% 53/140 [00:15<00:25,  3.35it/s]\u001b[A\n","Iteration:  39% 54/140 [00:16<00:25,  3.36it/s]\u001b[A\n","Iteration:  39% 55/140 [00:16<00:25,  3.36it/s]\u001b[A\n","Iteration:  40% 56/140 [00:16<00:24,  3.36it/s]\u001b[A\n","Iteration:  41% 57/140 [00:16<00:24,  3.38it/s]\u001b[A\n","Iteration:  41% 58/140 [00:17<00:24,  3.37it/s]\u001b[A\n","Iteration:  42% 59/140 [00:17<00:24,  3.37it/s]\u001b[A\n","Iteration:  43% 60/140 [00:17<00:23,  3.37it/s]\u001b[A\n","Iteration:  44% 61/140 [00:18<00:23,  3.37it/s]\u001b[A\n","Iteration:  44% 62/140 [00:18<00:23,  3.37it/s]\u001b[A\n","Iteration:  45% 63/140 [00:18<00:22,  3.37it/s]\u001b[A\n","Iteration:  46% 64/140 [00:19<00:22,  3.36it/s]\u001b[A\n","Iteration:  46% 65/140 [00:19<00:22,  3.38it/s]\u001b[A\n","Iteration:  47% 66/140 [00:19<00:21,  3.39it/s]\u001b[A\n","Iteration:  48% 67/140 [00:19<00:21,  3.39it/s]\u001b[A\n","Iteration:  49% 68/140 [00:20<00:21,  3.38it/s]\u001b[A\n","Iteration:  49% 69/140 [00:20<00:21,  3.37it/s]\u001b[A\n","Iteration:  50% 70/140 [00:20<00:20,  3.38it/s]\u001b[A\n","Iteration:  51% 71/140 [00:21<00:20,  3.38it/s]\u001b[A\n","Iteration:  51% 72/140 [00:21<00:20,  3.37it/s]\u001b[A\n","Iteration:  52% 73/140 [00:21<00:19,  3.36it/s]\u001b[A\n","Iteration:  53% 74/140 [00:22<00:19,  3.38it/s]\u001b[A\n","Iteration:  54% 75/140 [00:22<00:19,  3.38it/s]\u001b[A\n","Iteration:  54% 76/140 [00:22<00:18,  3.39it/s]\u001b[A\n","Iteration:  55% 77/140 [00:22<00:18,  3.38it/s]\u001b[A\n","Iteration:  56% 78/140 [00:23<00:18,  3.38it/s]\u001b[A\n","Iteration:  56% 79/140 [00:23<00:18,  3.38it/s]\u001b[A\n","Iteration:  57% 80/140 [00:23<00:17,  3.36it/s]\u001b[A\n","Iteration:  58% 81/140 [00:24<00:17,  3.35it/s]\u001b[A\n","Iteration:  59% 82/140 [00:24<00:17,  3.36it/s]\u001b[A\n","Iteration:  59% 83/140 [00:24<00:16,  3.36it/s]\u001b[A\n","Iteration:  60% 84/140 [00:25<00:16,  3.36it/s]\u001b[A\n","Iteration:  61% 85/140 [00:25<00:16,  3.36it/s]\u001b[A\n","Iteration:  61% 86/140 [00:25<00:16,  3.37it/s]\u001b[A\n","Iteration:  62% 87/140 [00:25<00:15,  3.37it/s]\u001b[A\n","Iteration:  63% 88/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 89/140 [00:26<00:15,  3.38it/s]\u001b[A\n","Iteration:  64% 90/140 [00:26<00:14,  3.37it/s]\u001b[A\n","Iteration:  65% 91/140 [00:27<00:14,  3.38it/s]\u001b[A\n","Iteration:  66% 92/140 [00:27<00:14,  3.39it/s]\u001b[A\n","Iteration:  66% 93/140 [00:27<00:13,  3.39it/s]\u001b[A\n","Iteration:  67% 94/140 [00:27<00:13,  3.39it/s]\u001b[A\n","Iteration:  68% 95/140 [00:28<00:13,  3.39it/s]\u001b[A\n","Iteration:  69% 96/140 [00:28<00:12,  3.39it/s]\u001b[A\n","Iteration:  69% 97/140 [00:28<00:12,  3.39it/s]\u001b[A\n","Iteration:  70% 98/140 [00:29<00:12,  3.38it/s]\u001b[A\n","Iteration:  71% 99/140 [00:29<00:12,  3.39it/s]\u001b[A\n","Iteration:  71% 100/140 [00:29<00:11,  3.38it/s]\u001b[A\n","Iteration:  72% 101/140 [00:30<00:11,  3.36it/s]\u001b[A\n","Iteration:  73% 102/140 [00:30<00:11,  3.37it/s]\u001b[A\n","Iteration:  74% 103/140 [00:30<00:10,  3.37it/s]\u001b[A\n","Iteration:  74% 104/140 [00:30<00:10,  3.36it/s]\u001b[A\n","Iteration:  75% 105/140 [00:31<00:10,  3.37it/s]\u001b[A\n","Iteration:  76% 106/140 [00:31<00:10,  3.36it/s]\u001b[A\n","Iteration:  76% 107/140 [00:31<00:09,  3.37it/s]\u001b[A\n","Iteration:  77% 108/140 [00:32<00:09,  3.39it/s]\u001b[A\n","Iteration:  78% 109/140 [00:32<00:09,  3.39it/s]\u001b[A\n","Iteration:  79% 110/140 [00:32<00:08,  3.38it/s]\u001b[A\n","Iteration:  79% 111/140 [00:32<00:08,  3.38it/s]\u001b[A\n","Iteration:  80% 112/140 [00:33<00:08,  3.38it/s]\u001b[A\n","Iteration:  81% 113/140 [00:33<00:07,  3.38it/s]\u001b[A\n","Iteration:  81% 114/140 [00:33<00:07,  3.38it/s]\u001b[A\n","Iteration:  82% 115/140 [00:34<00:07,  3.39it/s]\u001b[A\n","Iteration:  83% 116/140 [00:34<00:07,  3.39it/s]\u001b[A\n","Iteration:  84% 117/140 [00:34<00:06,  3.37it/s]\u001b[A\n","Iteration:  84% 118/140 [00:35<00:06,  3.39it/s]\u001b[A\n","Iteration:  85% 119/140 [00:35<00:06,  3.37it/s]\u001b[A\n","Iteration:  86% 120/140 [00:35<00:05,  3.37it/s]\u001b[A\n","Iteration:  86% 121/140 [00:35<00:05,  3.37it/s]\u001b[A\n","Iteration:  87% 122/140 [00:36<00:05,  3.36it/s]\u001b[A\n","Iteration:  88% 123/140 [00:36<00:05,  3.37it/s]\u001b[A\n","Iteration:  89% 124/140 [00:36<00:04,  3.37it/s]\u001b[A\n","Iteration:  89% 125/140 [00:37<00:04,  3.39it/s]\u001b[A\n","Iteration:  90% 126/140 [00:37<00:04,  3.39it/s]\u001b[A\n","Iteration:  91% 127/140 [00:37<00:03,  3.37it/s]\u001b[A\n","Iteration:  91% 128/140 [00:38<00:03,  3.37it/s]\u001b[A\n","Iteration:  92% 129/140 [00:38<00:03,  3.39it/s]\u001b[A\n","Iteration:  93% 130/140 [00:38<00:02,  3.38it/s]\u001b[A\n","Iteration:  94% 131/140 [00:38<00:02,  3.37it/s]\u001b[A\n","Iteration:  94% 132/140 [00:39<00:02,  3.38it/s]\u001b[A\n","Iteration:  95% 133/140 [00:39<00:02,  3.39it/s]\u001b[A\n","Iteration:  96% 134/140 [00:39<00:01,  3.40it/s]\u001b[A\n","Iteration:  96% 135/140 [00:40<00:01,  3.39it/s]\u001b[A\n","Iteration:  97% 136/140 [00:40<00:01,  3.37it/s]\u001b[A\n","Iteration:  98% 137/140 [00:40<00:00,  3.37it/s]\u001b[A\n","Iteration:  99% 138/140 [00:40<00:00,  3.37it/s]\u001b[A\n","Iteration:  99% 139/140 [00:41<00:00,  3.37it/s]\u001b[A03/04/2022 01:39:35 - INFO - trainer -   ***** Running evaluation on dev dataset *****\n","03/04/2022 01:39:35 - INFO - trainer -     Num examples = 500\n","03/04/2022 01:39:35 - INFO - trainer -     Batch size = 64\n","\n","\n","Evaluating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 1/8 [00:00<00:01,  6.07it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 2/8 [00:00<00:01,  5.72it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 3/8 [00:00<00:00,  5.77it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 4/8 [00:00<00:00,  5.61it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 5/8 [00:00<00:00,  5.63it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 6/8 [00:01<00:00,  5.69it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 7/8 [00:01<00:00,  5.72it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 8/8 [00:01<00:00,  5.83it/s]\n","03/04/2022 01:39:37 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:39:37 - INFO - trainer -     intent_acc = 0.98\n","03/04/2022 01:39:37 - INFO - trainer -     loss = 0.20434305537492037\n","03/04/2022 01:39:37 - INFO - trainer -     sementic_frame_acc = 0.91\n","03/04/2022 01:39:37 - INFO - trainer -     slot_f1 = 0.973115137346581\n","03/04/2022 01:39:37 - INFO - trainer -     slot_precision = 0.9725467289719626\n","03/04/2022 01:39:37 - INFO - trainer -     slot_recall = 0.9736842105263158\n","03/04/2022 01:39:37 - INFO - transformers.configuration_utils -   Configuration saved in atis_model/config.json\n","03/04/2022 01:39:41 - INFO - transformers.modeling_utils -   Model weights saved in atis_model/pytorch_model.bin\n","03/04/2022 01:39:41 - INFO - trainer -   Saving model checkpoint to atis_model\n","\n","Iteration: 100% 140/140 [00:46<00:00,  2.98it/s]\n","Epoch: 100% 10/10 [07:40<00:00, 46.06s/it]\n","03/04/2022 01:39:41 - INFO - transformers.configuration_utils -   loading configuration file atis_model/config.json\n","03/04/2022 01:39:41 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"JointRoberta\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"atis\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","03/04/2022 01:39:41 - INFO - transformers.modeling_utils -   loading weights file atis_model/pytorch_model.bin\n","03/04/2022 01:39:52 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing JointRoberta.\n","\n","03/04/2022 01:39:52 - INFO - transformers.modeling_utils -   All the weights of JointRoberta were initialized from the model checkpoint at atis_model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use JointRoberta for predictions without further training.\n","03/04/2022 01:39:52 - INFO - trainer -   ***** Model Loaded *****\n","03/04/2022 01:39:52 - INFO - trainer -   ***** Running evaluation on test dataset *****\n","03/04/2022 01:39:52 - INFO - trainer -     Num examples = 893\n","03/04/2022 01:39:52 - INFO - trainer -     Batch size = 64\n","Evaluating: 100% 14/14 [00:02<00:00,  5.76it/s]\n","03/04/2022 01:39:55 - INFO - trainer -   ***** Eval results *****\n","03/04/2022 01:39:55 - INFO - trainer -     intent_acc = 0.9776035834266518\n","03/04/2022 01:39:55 - INFO - trainer -     loss = 0.28787213856620447\n","03/04/2022 01:39:55 - INFO - trainer -     sementic_frame_acc = 0.8790593505039194\n","03/04/2022 01:39:55 - INFO - trainer -     slot_f1 = 0.9552974304822246\n","03/04/2022 01:39:55 - INFO - trainer -     slot_precision = 0.9546253957087584\n","03/04/2022 01:39:55 - INFO - trainer -     slot_recall = 0.9559704121169426\n"]}]},{"cell_type":"code","source":["!python3 predict.py --input_file /content/drive/MyDrive/NLP_Self/Intent_Detection_&_Slot_Filling/sample_pred_in.txt --output_file /content/drive/MyDrive/NLP_Self/Intent_Detection_&_Slot_Filling/sample_pred_out.txt --model_dir /content/drive/MyDrive/NLP_Self/Intent_Detection_&_Slot_Filling/atis_model"],"metadata":{"id":"azDyRbuBnJTP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UV9gTy9oe1f","executionInfo":{"status":"ok","timestamp":1646358822517,"user_tz":300,"elapsed":315,"user":{"displayName":"nihal antony","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpJB54aGbXtcirQ54x0HCtSxafskicA4J1MzA0tA=s64","userId":"04347007925849631634"}},"outputId":"99720fb3-5423-4753-c584-15e2f2fbbbfd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["atis_model\t\t   LICENSE     __pycache__\t   trainer.py\n","data\t\t\t   main.py     README.md\t   utils.py\n","data_loader.py\t\t   model       requirements.txt\n","Intent+Slot_filling.ipynb  predict.py  sample_pred_in.txt\n"]}]},{"cell_type":"code","source":["!python3 predict.py --input_file sample_pred_in.txt --output_file sample_pred_out.txt --model_dir atis_model"],"metadata":{"id":"6cNtHsBpv3z-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646358927480,"user_tz":300,"elapsed":18849,"user":{"displayName":"nihal antony","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpJB54aGbXtcirQ54x0HCtSxafskicA4J1MzA0tA=s64","userId":"04347007925849631634"}},"outputId":"3e5ef6bb-01fa-4685-f6d8-9b44d3207245"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["03/04/2022 01:55:11 - INFO - transformers.configuration_utils -   loading configuration file atis_model/config.json\n","03/04/2022 01:55:11 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"JointRoberta\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"atis\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","03/04/2022 01:55:11 - INFO - transformers.modeling_utils -   loading weights file atis_model/pytorch_model.bin\n","03/04/2022 01:55:22 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing JointRoberta.\n","\n","03/04/2022 01:55:22 - INFO - transformers.modeling_utils -   All the weights of JointRoberta were initialized from the model checkpoint at atis_model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use JointRoberta for predictions without further training.\n","03/04/2022 01:55:25 - INFO - __main__ -   ***** Model Loaded *****\n","03/04/2022 01:55:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, data_dir='./data', do_eval=True, do_train=True, dropout_rate=0.1, eval_batch_size=64, gradient_accumulation_steps=1, ignore_index=0, intent_label_file='intent_label.txt', learning_rate=5e-05, logging_steps=200, max_grad_norm=1.0, max_seq_len=50, max_steps=-1, model_dir='atis_model', model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=10.0, save_steps=200, seed=1234, slot_label_file='slot_label.txt', slot_loss_coef=1.0, slot_pad_label='PAD', task='atis', train_batch_size=32, use_crf=False, warmup_steps=0, weight_decay=0.0)\n","03/04/2022 01:55:25 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","03/04/2022 01:55:25 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","Predicting: 100% 1/1 [00:00<00:00, 28.95it/s]\n","03/04/2022 01:55:26 - INFO - __main__ -   Prediction Done!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"m00tKNojokBY"},"execution_count":null,"outputs":[]}]}